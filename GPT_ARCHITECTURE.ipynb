{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPLEMENTING A GPT MODEL FROM SCRATCH TO GENERATE TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257, # Vocabulary size\n",
    "    \"context_length\": 1024, # Context length\n",
    "    \"emb_dim\": 768,  # Embedding dimension\n",
    "    \"n_heads\": 12,   # Number of attention heads\n",
    "    \"n_layers\":12,   # Number of layers\n",
    "    \"drop_rate\": 0.1, # Dropout rate\n",
    "    \"qkv_bias\": False  # Query-Key-Value bias\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT ARCHITECTURE PART 1 : DUMMY GPT MODEL CLASS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> \n",
    "Step 1: Use a placeholder for Transformer Block\n",
    "\n",
    "Step 2: Use a placeholder for LayerNorm\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DummyGPTModel(nn.Module):\n",
    "    def __init__(self,cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"],cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "        # Use a placeholder for Transformer Block\n",
    "\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"]) ]\n",
    "        )\n",
    "\n",
    "        # Use a placeholdr for LayerNorm\n",
    "        \n",
    "        self.final_norm = DummyLayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    def forward(self,in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "class DummyTransformerBlock(nn.Module):\n",
    "    def __init__(self,cfg):\n",
    "        super().__init__()\n",
    "        # A simple placeholder\n",
    "\n",
    "    def forward(self,x):\n",
    "        # This block does nothing and just returns its input.\n",
    "        return x \n",
    "    \n",
    "\n",
    "class DummyLayerNorm(nn.Module):\n",
    "    def __init__(self,normalized_shape,eps=1e-5):\n",
    "        super().__init__()\n",
    "        # The parameters here are just to mimic the LayerNorm interface.\n",
    "\n",
    "    def forward(self,x):\n",
    "        # This  layer does nothing and  just returns its input.\n",
    "        return x \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 4040, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "batch = []\n",
    "txt1 = \"Every efforts moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch,dim=0)\n",
    "print(batch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2 : CREATE AN INSTANCE OF  GPT MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GPTModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m123\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mGPTModel\u001b[49m(GPT_CONFIG_124M)\n\u001b[0;32m      3\u001b[0m logits \u001b[38;5;241m=\u001b[39m model(batch)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m,logits\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'GPTModel' is not defined"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "logits = model(batch)\n",
    "print(\"Output shape:\",logits.shape)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT ARCHITECTURE PART 2 : LAYER NORMALIZATON\n",
    "\n",
    "#### Explanation with a simple example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
      "        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "batch_example = torch.randn(2,5) #A\n",
    "layer = nn.Sequential(nn.Linear(5,6),nn.ReLU())\n",
    "out = layer(batch_example)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "The neural network layer we have coded consists of a Linear layer followed by a non-linear activation function (RELU). \n",
    " </div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Before we apply layer normalization to these outputs, let's examine the mean and variance:\n",
    " </div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[0.1324],\n",
      "        [0.2170]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[0.0231],\n",
      "        [0.0398]], grad_fn=<VarBackward0>)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "mean = out.mean(dim=-1,keepdim=True)\n",
    "var = out.var(dim=-1,keepdim=True)\n",
    "print(\"Mean:\\n\",mean)\n",
    "print(\"Variance:\\n\",var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "The first row in the mean tensor above contains the mean value for the first input row, and the second output row contains the mean for the second input row.\n",
    " </div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized layer outputts:\n",
      " tensor([[ 0.6159,  1.4126, -0.8719,  0.5872, -0.8719, -0.8719],\n",
      "        [-0.0189,  0.1121, -1.0876,  1.5173,  0.5647, -1.0876]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "Mean:\n",
      " tensor([[    0.0000],\n",
      "        [    0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "out_norm = ( out - mean)/ torch.sqrt(var)\n",
    "mean = out_norm.mean(dim=-1,keepdim=True)\n",
    "var = out_norm.var(dim=-1,keepdim=True)\n",
    "print(\"Normalized layer outputts:\\n\",out_norm)\n",
    "print(\"Mean:\\n\",mean)\n",
    "print(\"Variance:\\n\",var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[    0.0000],\n",
      "        [    0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(sci_mode=False)\n",
    "print(\"Mean:\\n\",mean)\n",
    "print(\"Variance:\\n\",var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# LayerNorm implementation\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Let's now try the LayerNorm module in practice and apply it to the batch input:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[    -0.0000],\n",
      "        [     0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "ln = LayerNorm(emb_dim=5)\n",
    "out_ln = ln(batch_example)\n",
    "mean = out_ln.mean(dim=-1,keepdim=True)\n",
    "var = out_ln.var(dim=-1,unbiased=False,keepdim=True)\n",
    "print(\"Mean:\\n\",mean)\n",
    "print(\"Variance:\\n\",var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARCHITECTURE PART 3 : FEEDFORWARD NEURAL NETWORK WITH GELU ACTIVATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Let's implement the GELU activation function approximation used by GPT-2:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self,x):\n",
    "        return 0.5*x*(1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0/torch.pi))*\n",
    "            (x+ 0.044715*torch.pow(x,3))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "To get an idea of what this  GELU function looks like and how it compares to the ReLu function, let's plot these functions side by side:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxYAAAEiCAYAAABkykQ1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABn7UlEQVR4nO3deVxU9foH8M8My7AJimwKiIqKOyqmgbmVgltFqdmioqapYWWmJlYueZOb5pa7lZKk130pNZUsUn/u4IYLuYAosimrLMMwc35/IJMIKMN2zgyf9+s1r3vnzDlznmcm58tzznm+RyYIggAiIiIiIqJKkIsdABERERER6T8WFkREREREVGksLIiIiIiIqNJYWBARERERUaWxsCAiIiIiokpjYUFERERERJXGwoKIiIiIiCqNhQUREREREVUaCwsiIiIiIqo0FhZEpZgzZw5kMpko+w4JCYFMJkNsbGyN77ugoADTp0+Hq6sr5HI5/P39azyG8hDzMyKi2m3UqFFo3LixKPsWc2x69OgRxo4dCycnJ8hkMkyePFmUOJ5HzM+IWFjUSjExMZg0aRJatGgBCwsLWFhYoHXr1ggMDMSlS5eKrVv0D7SsR2JiIgAgNjYWMpkM3333XZn7bdy4MQYNGlTqa+fOnYNMJkNISEiV5fk8OTk5mDNnDsLDw2tsn0+aP38+9uzZI8q+y7J+/XosXLgQQ4YMwc8//4xPP/1U1Hik+BkRGbKior3oYWxsDGdnZ4waNQrx8fEVes/w8HDIZDLs2LGjzHVkMhkmTZpU6ms7duyATCar0d/q+/fvY86cObhw4UKN7bOI2GNTWebPn4+QkBBMnDgRoaGhGDFihGixSPUzIsBY7ACoZu3btw/Dhg2DsbEx3nvvPXh6ekIul+P69evYtWsXVq9ejZiYGLi5uRXbbvXq1bCysirxfnXr1q2hyKteTk4O5s6dCwDo1atXsde+/PJLzJgxo1r3P3/+fAwZMqTEWYERI0bg7bffhkKhqNb9l+bPP/+Es7MzlixZUuP7Lo0UPyOi2uDrr79GkyZNkJeXh1OnTiEkJATHjx9HVFQUzMzMxA6v2t2/fx9z585F48aN0aFDh2Kv/fDDD9BoNNW2b7HHprL8+eefePHFFzF79mxR9v8kqX5GxMKiVrl16xbefvttuLm54ciRI2jQoEGx17/99lusWrUKcnnJE1lDhgyBnZ1dTYUqOmNjYxgbi/PPw8jICEZGRqLsOzk5WS+KRTE/I6LaoH///ujcuTMAYOzYsbCzs8O3336LX3/9FW+99ZbI0YnLxMREtH2LOTYlJyejdevWouxbF2J+RsRLoWqVBQsWIDs7Gxs2bChRVACF/xg//vhjuLq6ihBd+aSmpmLq1Klo164drKysYG1tjf79++PixYsl1s3Ly8OcOXPQokULmJmZoUGDBnjzzTdx69YtxMbGwt7eHgAwd+5c7Wn/OXPmACh5jWbbtm3Ru3fvEvvQaDRwdnbGkCFDtMu+++47+Pj4oH79+jA3N4eXl1eJSwBkMhmys7Px888/a/c9atQoAGX3D6xatQpt2rSBQqFAw4YNERgYiPT09GLr9OrVC23btsXVq1fRu3dvWFhYwNnZGQsWLHjm51p0Kdtff/2FK1euaGMKDw/XXsbw9Cnnom2evHxt1KhRsLKyQnx8PPz9/WFlZQV7e3tMnToVarW6xGe3bNkytGvXDmZmZrC3t0e/fv1w7tw5SX5GRLVZ9+7dARQeoHrS9evXMWTIENja2sLMzAydO3fGr7/+KkaIuHPnDj788EN4eHjA3Nwc9evXx9ChQ0vtxUpPT8enn36Kxo0bQ6FQwMXFBSNHjsSDBw8QHh6OF154AQAwevRo7e9P0W/dkz0WKpUKtra2GD16dIl9ZGZmwszMDFOnTgUA5OfnY9asWfDy8oKNjQ0sLS3RvXt3/PXXX9ptdB2bgMLeuHnz5sHd3R0KhQKNGzfGzJkzoVQqi61XdDny8ePH0aVLF5iZmaFp06bYuHHjMz/XojEgJiYG+/fv18YUGxtb5m9xaeOGLr+9VTl+18RnRP9iYVGL7Nu3D82aNUPXrl113jY1NRUPHjwo9nj6D7aacPv2bezZsweDBg3C4sWLMW3aNFy+fBk9e/bE/fv3teup1WoMGjQIc+fOhZeXFxYtWoRPPvkEGRkZiIqKgr29PVavXg0AeOONNxAaGorQ0FC8+eabpe532LBhOHr0qLanpMjx48dx//59vP3229ply5YtQ8eOHfH1119j/vz5MDY2xtChQ7F//37tOqGhoVAoFOjevbt23+PHjy8z7zlz5iAwMBANGzbEokWLMHjwYKxduxa+vr5QqVTF1k1LS0O/fv3g6emJRYsWoWXLlvj888/x+++/l/n+9vb2CA0NRcuWLeHi4qKNqVWrVmVuUxa1Wg0/Pz/Ur18f3333HXr27IlFixZh3bp1xdZ7//33MXnyZLi6uuLbb7/FjBkzYGZmhlOnTknyMyKqzYr+cKxXr5522ZUrV/Diiy/i2rVrmDFjBhYtWgRLS0v4+/tj9+7dNR7j2bNnceLECbz99tv4/vvvMWHCBBw5cgS9evVCTk6Odr1Hjx6he/fuWL58OXx9fbFs2TJMmDAB169fx71799CqVSt8/fXXAIAPPvhA+/vTo0ePEvs0MTHBG2+8gT179iA/P7/Ya3v27IFSqdSOD5mZmfjxxx/Rq1cvfPvtt5gzZw5SUlLg5+en7eXQdWwCCs8ozZo1C506dcKSJUvQs2dPBAcHFxuXity8eRNDhgxB3759sWjRItSrVw+jRo3ClStXynz/Vq1aITQ0FHZ2dujQoYM2pqI/7nVRnt/eqh6/a+IzoicIVCtkZGQIAAR/f/8Sr6WlpQkpKSnaR05Ojva12bNnCwBKfXh4eGjXi4mJEQAICxcuLDMGNzc3YeDAgaW+dvbsWQGAsGHDhmfmkZeXJ6jV6mLLYmJiBIVCIXz99dfaZevXrxcACIsXLy7xHhqNRhAEQUhJSREACLNnzy6xTlHeRaKjowUAwvLly4ut9+GHHwpWVlbFPrMn/78gCEJ+fr7Qtm1b4eWXXy623NLSUggICCix7w0bNggAhJiYGEEQBCE5OVkwNTUVfH19i+W+YsUKAYCwfv167bKePXsKAISNGzdqlymVSsHJyUkYPHhwiX09rWfPnkKbNm2KLfvrr78EAMJff/1VbHnRd/7kdxYQECAAKPZdCIIgdOzYUfDy8tI+//PPPwUAwscff1wihqLvRxCk+RkRGbKif1t//PGHkJKSIty9e1fYsWOHYG9vLygUCuHu3bvadV955RWhXbt2Ql5ennaZRqMRfHx8hObNm2uXFf2GbN++vcz9AhACAwNLfW379u2l/gY97enfXkEQhJMnT5b49z5r1iwBgLBr164S6xf9/jxrTAoICBDc3Ny0zw8dOiQAEH777bdi6w0YMEBo2rSp9nlBQYGgVCqLrZOWliY4OjoKY8aM0S7TZWy6cOGCAEAYO3ZssfWmTp0qABD+/PNP7TI3NzcBgHD06FHtsuTkZEGhUAifffZZiX09rbQx/Onf4iKljRvl/e2t6vG7Jj8jEgSesaglMjMzAaDUBuxevXrB3t5e+1i5cmWJdXbu3ImwsLBijw0bNlR73E9TKBTaHhC1Wo2HDx/CysoKHh4eiIyMLBavnZ0dPvrooxLvUZFp6Fq0aIEOHTpg69at2mVqtRo7duzAq6++CnNzc+3yJ/9/WloaMjIy0L1792Lx6eKPP/5Afn4+Jk+eXKz/Zdy4cbC2ti52JgQo/I6HDx+ufW5qaoouXbrg9u3bFdp/RUyYMKHY8+7duxfb/86dOyGTyUptAqzI96OPnxGRlPXp0wf29vZwdXXFkCFDYGlpiV9//RUuLi4ACs9i//nnn3jrrbeQlZWlPZP98OFD+Pn54caNGxWeRaqinvztValUePjwIZo1a4a6deuWGB88PT3xxhtvlHiPivz+vPzyy7Czsys2PqSlpSEsLAzDhg3TLjMyMoKpqSmAwktBU1NTUVBQgM6dO1d4fDhw4AAAYMqUKcWWf/bZZwBQ4revdevW2svagMIzJB4eHjX221ee396qHr/17TPSd+xuqSXq1KkDoPAU8NPWrl2LrKwsJCUlFfsH/6QePXrUSPP28340iq7LX7VqFWJiYopdt1+/fn3t/7916xY8PDyqtIFr2LBhmDlzJuLj4+Hs7Izw8HAkJycXGziAwkvO/vOf/+DChQvFrt+s6Lzad+7cAQB4eHgUW25qaoqmTZtqXy/i4uJSYl/16tUrMZVwdSnql3h6/2lpadrnt27dQsOGDWFra1sl+9S3z4hI6lauXIkWLVogIyMD69evx9GjR4vNwnbz5k0IgoCvvvoKX331VanvkZycDGdn5yqL6Xm/obm5uQgODsaGDRsQHx8PQRC0r2VkZGj//61btzB48OAqi8vY2BiDBw/G5s2boVQqoVAosGvXLqhUqhLjw88//4xFixbh+vXrxS7RbNKkSYX2fefOHcjlcjRr1qzYcicnJ9StW7fEb1+jRo1KvMfTv8/VqTy/vVU9fuvbZ6TvWFjUEjY2NmjQoAGioqJKvFbUc1HdNxszMzNDbm5uqa8VXf/6vGkM58+fj6+++gpjxozBvHnzYGtrC7lcjsmTJ1fr9H9AYWERFBSE7du3Y/Lkydi2bRtsbGzQr18/7TrHjh3Da6+9hh49emDVqlVo0KABTExMsGHDBmzevLla4ytS1mxJTw6yuihrMH+6Gft5+5eSqv6MiAxNly5dtLNC+fv746WXXsK7776L6OhoWFlZaX9vp06dCj8/v1Lf4+k/5J5FoVBUenz46KOPsGHDBkyePBne3t6wsbGBTCbD22+/Xe3jw9tvv421a9fi999/h7+/P7Zt24aWLVvC09NTu84vv/yCUaNGwd/fH9OmTYODgwOMjIwQHBxcoileV+U9cCXV8aEmfnvF+oxqGxYWtcjAgQPx448/4syZM+jSpUuN79/NzQ1Xr14t9bXo6GjtOs+yY8cO9O7dGz/99FOx5enp6cXOqLi7u+P06dNQqVRlTg2o6xmEJk2aoEuXLti6dSsmTZqEXbt2wd/fv9hRvJ07d8LMzAyHDh0qtry0y8bKu/+izyQ6OhpNmzbVLs/Pz0dMTAz69OmjUx66KmrWfLpZ/+mjPLpwd3fHoUOHkJqa+syzFvryGREZsqI/fnv37o0VK1ZgxowZ2n9nJiYmVfLvy83NTTsOPE2X8SEgIACLFi3SLsvLyyvx2+Xu7l7qQbYn6To+9OjRAw0aNMDWrVvx0ksv4c8//8QXX3xRIr6mTZti165dxd7/6UtCddm3m5sbNBoNbty4UWyyjaSkJKSnpz/3M6us6hofqnL8Fvszqm3YY1GLTJ8+HRYWFhgzZgySkpJKvF7d1fiAAQNw7969EndSViqV+PHHH+Hg4IBOnTo98z2MjIxKxLl9+/YS1/IOHjwYDx48wIoVK0q8R9H2FhYWAEr+ID7LsGHDcOrUKaxfvx4PHjwocZrbyMgIMpms2NGa2NjYUu8ebWlpWa599+nTB6ampvj++++L5f7TTz8hIyMDAwcOLHf8FeHm5gYjIyMcPXq02PJVq1ZV+D0HDx4MQRC0Nzh60pM56stnRGToevXqhS5dumDp0qXIy8uDg4MDevXqhbVr1yIhIaHE+ikpKTq9/4ABA3Dq1ClEREQUW56eno5NmzahQ4cOcHJyeuZ7lDY+LF++vMTR88GDB+PixYulzlxVtL2lpaV2/+Uhl8sxZMgQ/PbbbwgNDUVBQUGp48OT+wCA06dP4+TJk8XW02VsGjBgAABg6dKlxZYvXrwYAKr9t8/d3R0Aio0ParW6xCyAuqjq8Vvsz6i24RmLWqR58+bYvHkz3nnnHXh4eGjvvC0IAmJiYrB582bI5XJtc96TduzYUWrjd9++feHo6Kh9fuTIEeTl5ZVYz9/fHx988AHWr1+PoUOHYsyYMejYsSMePnyIrVu3IioqChs3btQ2tpVl0KBB+PrrrzF69Gj4+Pjg8uXL2LRpU7Gj1AAwcuRIbNy4EVOmTMGZM2fQvXt3ZGdn448//sCHH36I119/Hebm5mjdujW2bt2KFi1awNbWFm3btkXbtm3L3P9bb72FqVOnYurUqbC1tS1xpG7gwIFYvHgx+vXrh3fffRfJyclYuXIlmjVrVuL6fS8vL/zxxx9YvHgxGjZsiCZNmpQ6FbC9vT2CgoIwd+5c9OvXD6+99hqio6OxatUqvPDCC2X2xVQVGxsbDB06FMuXL4dMJoO7uzv27duH5OTkCr9n7969MWLECHz//fe4ceMG+vXrB41Gg2PHjqF3796YNGkSAP35jIhqg2nTpmHo0KEICQnBhAkTsHLlSrz00kto164dxo0bh6ZNmyIpKQknT57EvXv3StxfaOfOnbh+/XqJ9w0ICMCMGTOwfft29OjRA+PHj0fLli1x//59hISEICEhoVyThQwaNAihoaGwsbFB69atcfLkSfzxxx/F+u+K8tixY4d2LPLy8kJqaip+/fVXrFmzBp6ennB3d0fdunWxZs0a1KlTB5aWlujateszeyGGDRuG5cuXY/bs2WjXrl2J6boHDRqEXbt24Y033sDAgQMRExODNWvWoHXr1sX6H3UZmzw9PREQEIB169YhPT0dPXv2xJkzZ/Dzzz/D39+/1PsvVaU2bdrgxRdfRFBQkPYM9JYtW1BQUFDh96zq8Vvsz6jWqeFZqEgCbt68KUycOFFo1qyZYGZmJpibmwstW7YUJkyYIFy4cKHYus+abhZPTCVXNPVoWY/Q0FBBEAqn1vv000+FJk2aCCYmJoK1tbXQu3dv4ffffy9X7Hl5ecJnn30mNGjQQDA3Nxe6desmnDx5UujZs6fQs2fPYuvm5OQIX3zxhXZfTk5OwpAhQ4Rbt25p1zlx4oTg5eUlmJqaFpu67unp6p7UrVu3UqeuK/LTTz8JzZs3FxQKhdCyZUthw4YNpb7f9evXhR49egjm5uYCAO20qmVN37dixQqhZcuWgomJieDo6ChMnDhRSEtLK7ZOadPFCkLJ6RHLUtb2KSkpwuDBgwULCwuhXr16wvjx44WoqKhSp5u1tLQssX1p+RcUFAgLFy4UWrZsKZiamgr29vZC//79hYiICO06UvyMiAxZ0b+ts2fPlnhNrVYL7u7ugru7u1BQUCAIgiDcunVLGDlypODk5CSYmJgIzs7OwqBBg4QdO3ZotyuaerSsx7FjxwRBEIR79+4JY8eOFZydnQVjY2PB1tZWGDRokHDq1KlyxZ6WliaMHj1asLOzE6ysrAQ/Pz/h+vXrgpubW4lpqx8+fChMmjRJcHZ2FkxNTQUXFxchICBAePDggXadvXv3Cq1btxaMjY2L/daV9Vuh0WgEV1dXAYDwn//8p9TX58+fL7i5uQkKhULo2LGjsG/fvlLfT5exSaVSCXPnztWOda6urkJQUFCxaYAFoewp30sbP0tT1va3bt0S+vTpIygUCsHR0VGYOXOmEBYWVup0s+X97a3q8bumPiMSBJkgsBuFiIiIiIgqhz0WRERERERUaSwsiIiIiIio0lhYEBERERFRpbGwICIiIiKiSmNhQURERERElcbCgoiIiIiIKq3W3SBPo9Hg/v37qFOnjk63hCciMmSCICArKwsNGzaEXF57jzlxjCAiKk6X8aHWFRb379+Hq6ur2GEQEUnS3bt34eLiInYYouEYQURUuvKMD7WusKhTpw6Awg/H2tpap21VKhUOHz4MX19fmJiYVEd4NcIQ8mAO0mEIeRhCDkDl8sjMzISrq6v2N7K2qu1jBHOQDkPIwxByAAwjj5oaH2pdYVF0atva2rpCg4aFhQWsra319j8swDDyYA7SYQh5GEIOQNXkUdsv/6ntYwRzkA5DyMMQcgAMI4+aGh9q74W0RERERERUZVhYEBERERFRpYlaWKxevRrt27fXnnL29vbG77///sxttm/fjpYtW8LMzAzt2rXDgQMHaihaIiKqKRwfiIj0j6iFhYuLC/773/8iIiIC586dw8svv4zXX38dV65cKXX9EydO4J133sH777+P8+fPw9/fH/7+/oiKiqrhyImIqDpxfCAi0j+iFhavvvoqBgwYgObNm6NFixb45ptvYGVlhVOnTpW6/rJly9CvXz9MmzYNrVq1wrx589CpUyesWLGihiMnIqLqxPGBiEj/SGZWKLVaje3btyM7Oxve3t6lrnPy5ElMmTKl2DI/Pz/s2bOnzPdVKpVQKpXa55mZmQAKu+NVKpVOMRatr+t2UmMIeTAH6TCEPAwiB7UGX++7ihbqiuUh5dyra3wgIqotjt14gD/vy9BfEKp1P6IXFpcvX4a3tzfy8vJgZWWF3bt3o3Xr1qWum5iYCEdHx2LLHB0dkZiYWOb7BwcHY+7cuSWWHz58GBYWFhWKOSwsrELbSY0h5MEcpMMQ8tDnHLbdluP/kuSorzCCjWkYjHU8H52Tk1M9gVVCdY8PAA8+PY05SIch5GEIOQD6n8ed1BxM3nYJmXlG6Hw2Dm93cdNpe13yFr2w8PDwwIULF5CRkYEdO3YgICAAf//9d5mDh66CgoKKHcUqusmHr69vheYoDwsLQ9++ffV2HmPAMPJgDtJhCHnoew6/nI7D/528DhmANxpr0N9P9zyK/qCWkuoeHwAefCoLc5AOQ8jDEHIA9DMPpRpYEmWEzDwZ3KwEWCRfwYEDpfeqlUWXA0+iFxampqZo1qwZAMDLywtnz57FsmXLsHbt2hLrOjk5ISkpqdiypKQkODk5lfn+CoUCCoWixHITE5MK/wFRmW2lxBDyYA7SYQh56GMOx26k4D8HogEAn/VtDtdH1yqUhxTzru7xAeDBp6cxB+kwhDwMIQdAf/MQBAGTt11CQk4S6luaYkyLnGo/8CR6YfE0jUZT7LT0k7y9vXHkyBFMnjxZuywsLKzMa26JiAzZ7ZRHCNwUCbVGwJudnPFB98b4/fdrYodVbapjfODBp9IxB+kwhDwMIQdA//JY8/ctHIhKgrFchhXveCL5yslqP/AkamERFBSE/v37o1GjRsjKysLmzZsRHh6OQ4cOAQBGjhwJZ2dnBAcHAwA++eQT9OzZE4sWLcLAgQOxZcsWnDt3DuvWrRMzDSKiGpeRo8LYn88hM68AnRrVxfw32kEGjdhhVRmOD0REFXf0nxQsOHgdADD7tTbo7FYPOl4BVSGiFhbJyckYOXIkEhISYGNjg/bt2+PQoUPo27cvACAuLg5y+b8diD4+Pti8eTO+/PJLzJw5E82bN8eePXvQtm1bsVIgIqpxBWoNJv0vErcfZKOhjRnWjugMMxMjqFSGU1hwfCAiqpi4hzn46H/noRGAoV4uGN61EQoKCmpk36IWFj/99NMzXw8PDy+xbOjQoRg6dGg1RUREJH3/2X8Nx248gLmJEX4I6Az7OiUv5dF3HB+IiHSXk1+AD0LPISNXBU/Xupjn3xYymazG9i/qDfKIiEg3m0/HIeRELABgyTBPtGloI25AREQkCYIg4POdl3E9MQt2VqZYM7wTzEyMajQGFhZERHri5K2HmLU3CgDwWd8W6Ne2gcgRERGRVPx4LAa/XbwPY7kMq97zQgMb8xqPgYUFEZEeiHuYg4mbIlCgEfCqZ0NMermZ2CEREZFEHL/xAMGPZwX8alBrdGliK0ocLCyIiCQuK0+FsRvPIj1HhfYuNlg4pH2NXjNLRETSdTc1B5P+FwmNAAzxcsFIb93urF2VWFgQEUmYWiNg8pYL+CfpERytFfhhZOcav2aWiIikKTdfjfGhEdoDT/+p4Wbtp7GwICKSsIWHonHkejIUxnKsG9EZjtZmYodEREQSIAgCZuy6hKsJmahvaYo1w71EP/DEwoKISKJ2Rd7Dmr9vAQAWDGkPT9e64gZERESS8dPxGOy9cB9GchlWvtcJDevWfLP201hYEBFJ0Pm4NMzYdRkAENjbHa93cBY5IiIikooTNx8g+PfCO2t/ObAVXmxaX+SICrGwICKSmISMXHwQGoH8Ag36tnbEZ309xA6JiIgk4l5aDib97zzUGgFvdnLGKJ/GYoekxcKCiEhC8lRqfLAxAilZSrR0qoOlwzpALucMUEREVDhGjA+NQGp2Pto6W2P+G+0kNUsgCwsiIokQBAHTdlzC5fgM2Fqa4oeRnWGpMBY7LCIikgBBEDBz12VcuZ8JW4k0az+NhQURkUSsCr/1xF1TO8HV1kLskIiISCJCTsRi1/l4GMllWPFuR7jUk94YwcKCiEgCwq4m4bvD0QCAua+3kUwjHhERie/U7Yf4z/7CO2vPHNAKPu52IkdUOhYWREQii07MwuQt5yEIwEhvN7zXVby7phIRkbTEp+cicFMk1BoB/h0aYky3xmKHVCYWFkREIkrLzsfYjWeRna+Gd9P6+GpQa7FDIiIiichTqTHxlwg8zM5H6wbWCH6zvaSatZ/GwoKISCQqtQYfborE3dRcuNqaY9V7nWBixJ9lIiIqbNb+YncULt3LQD0LE6wd4QVzU2k1az+NIxgRkUj+s+8qTt5+CEtTI/w48gXUszQVOyQiIpKIjSfvYGfkPchlwIp39WNCDxYWREQi+N+ZOPx88g4AYMmwDvBwqiNyREREJBWnbz/EvH1XAQBB/VuhWzNpNms/TdTCIjg4GC+88ALq1KkDBwcH+Pv7Izo6+pnbhISEQCaTFXuYmZnVUMRERJV3NjYVs/ZGAQCm+raAbxsnkSMiIiKpSMjIReDmSBRoBLzm2RBjuzcRO6RyE7Ww+PvvvxEYGIhTp04hLCwMKpUKvr6+yM7OfuZ21tbWSEhI0D7u3LlTQxETEVVOfHouJoRGQKUWMLB9AwT2biZ2SEREJBF5KjUmhEbgwaN8tGpgjW8HS7tZ+2miFhYHDx7EqFGj0KZNG3h6eiIkJARxcXGIiIh45nYymQxOTk7ah6OjYw1FTERUcbn5aowPPaed3WPhEP0aMGoSz2gTUW0jCAK+2hOFi/cyYGNugrXDpd+s/TRJ9VhkZGQAAGxtbZ+53qNHj+Dm5gZXV1e8/vrruHLlSk2ER0RUYYIg4POdlxAVnwlbS1OsG+kFC1NjscOSLJ7RJqLa5pfTcdgeUdSs3RGN6ku/WftpkhnVNBoNJk+ejG7duqFt27Zlrufh4YH169ejffv2yMjIwHfffQcfHx9cuXIFLi4uJdZXKpVQKpXa55mZmQAAlUoFlUqlU4xF6+u6ndQYQh7MQToMIY+ayGHdsRj8evE+jOUyfD+sPRytTKp8f5XJQ2rf38GDB4s9DwkJgYODAyIiItCjR48ytys6o01EpE/OxqZi7q+FB8o/79cS3ZvbixxRxUimsAgMDERUVBSOHz/+zPW8vb3h7e2tfe7j44NWrVph7dq1mDdvXon1g4ODMXfu3BLLDx8+DAuLilWCYWFhFdpOagwhD+YgHYaQR3XlcDVNhnXX5QBk8HcrwMNrp3DgWrXsCkDF8sjJyamGSKqOrme0NRoNOnXqhPnz56NNmzY1ESIRUYUkZebhw02FzdoD2zfABz2aih1ShUmisJg0aRL27duHo0ePlnrW4VlMTEzQsWNH3Lx5s9TXg4KCMGXKFO3zzMxMuLq6wtfXF9bW1jrtS6VSISwsDH379oWJiYlO20qJIeTBHKTDEPKozhxiHmTjy7WnIaAAwzq7YN5rraqtr6IyeRSdzZWi6jqjDfCs9tOYg3QYQh6GkANQvXkoCzQYH3oOKVlKeDha4ZvXWqGgoKDK91NTZ7RFLSwEQcBHH32E3bt3Izw8HE2a6D6dllqtxuXLlzFgwIBSX1coFFAoFCWWm5iYVPgPiMpsKyWGkAdzkA5DyKOqc8jKU2Hi5gvIyitAZ7d6mOffDqbG1d/aVpE8pPzdVdcZbYBntcvCHKTDEPIwhByA6sljyy05LiTLYWEk4K2G6fj7yOEq38eTqvuMtqiFRWBgIDZv3oy9e/eiTp06SExMBADY2NjA3NwcADBy5Eg4OzsjODgYAPD111/jxRdfRLNmzZCeno6FCxfizp07GDt2rGh5EBE9TaMR8OnWC7iVko0GNmZYPdyrRooKQ1OdZ7QBntV+GnOQDkPIwxByAKovjy1n7+HkyauQyYAV73mhe/PquwleTZ3RFrWwWL16NQCgV69exZZv2LABo0aNAgDExcVBLv93ME5LS8O4ceOQmJiIevXqwcvLCydOnEDr1q1rKmwiouda8sc/+ONaMhTGcqwd4QX7OiXPnFLZauKMNsCz2mVhDtJhCHkYQg5A1eYRcScNX+8vbLab5ueBl1s3qJL3fZ7qPqMt+qVQzxMeHl7s+ZIlS7BkyZJqioiIqPJ+v5yA5X8WHiUPfrMd2rvUFTcgPcQz2kRkqJIy8zDxl8IbpQ5o54SJPd3FDqnKSKJ5m4jIUFxPzMRn2y8CAN5/qQne7KTb5TtUiGe0icgQ5RdoMPGXCCRnKdHC0QoLh3ga1I1SWVgQEVWR9Jx8fLAxAjn5avi410dQ/5Zih6S3eEabiAzR3N+uIDIuHdZmxlg3ojMsFYb1pzg7CYmIqoBaI+Cj/51HXGoOXOqZY8W7nWBsxJ9YIiIqtOVMHDadjoNMBix7uyMa21mKHVKV46hHRFQFFh6KxrEbD2BmIse6EZ1ha2kqdkhERCQRkXFpmLW38M7aU3090Lulg8gRVQ8WFkRElbTv0n2s+fsWAGDhEE+0bqjbNKVERGS4krMKm7Xz1Rr0a+OED3sZTrP201hYEBFVwrWETEzbfgkAML5nU7zq2VDkiIiISCryCzQI3BSJpEwlmjtY4bu3DKtZ+2ksLIiIKig9Jx/jQyOQq1Kje3M7TPdjszYREf1r3r6rOBubhjoKY6wd4QUrA2vWfhoLCyKiClBrBHy85QLiUnPgamuO5e90hJHccI9CERGRbradvYvQU3cKm7Xf6YCm9lZih1TtWFgQEVXAosPROPpPCsxM5Fg7vDPqWrBZm4iICl24m44v90QBAD7t0wIvt3QUOaKawcKCiEhHv19OwKrwwmbtbwe3Z7M2ERFppWQpMSG0sFnbt7UjJvVuJnZINYaFBRGRDm4kZWHq4ztrj32pCV7v4CxyREREJBUqdWGzdmJmHtztLbHoLU/Ia9FlsiwsiIjKKTNPhfGhEch+fGftGbyzNhERPeGb/ddwJjYVVgpjrBvZGXXMTMQOqUaxsCAiKgeNRsCUrRdx+0E2nOsWNmvzztpERFRkR8Q9hJyIBQAsGdYB7rWgWftpHBWJiMphxV838ce1JJgay7F6eCfUt1KIHRIREUnEpXvpmLn7MgBgcp/m6Nu6djRrP42FBRHRc/x1PRlL/vgHAPAf/7Zo71JX3ICIiEgyHjx63KxdoEGfVg74+OXmYockGhYWRETPcOdhNj7Zch6CALzXtRHe6uwqdkhERCQRRc3a9zPy0NTeEouHdahVzdpPY2FBRFSG3Hw1JvwSicy8AnRsVBezXm0tdkhERCQh8w9cw+mYx83aIzrDupY1az+NhQURUSkEQcDM3ZdxLSETdlamWP2eFxTGRmKHRUREErEr8h42/F8sAGDRW55o5lD7mrWfxsKCiKgUG0/ewe7z8TCSy7Di3U5wsjETOyQiIpKIqPgMBO0qbNb++OVm8GvjJHJE0iBqYREcHIwXXngBderUgYODA/z9/REdHf3c7bZv346WLVvCzMwM7dq1w4EDB2ogWiKqLSLupGLevqsAgKD+LfFi0/oiR0RERFLx8JES40MjoCzQ4JWWDpjcp4XYIUmGqIXF33//jcDAQJw6dQphYWFQqVTw9fVFdnZ2mducOHEC77zzDt5//32cP38e/v7+8Pf3R1RUVA1GTkSGKjkrDx9uikSBRsDA9g3w/ktNxA6JiIgkokCtwaTN5xGfnosmdmzWfpqxmDs/ePBgsechISFwcHBAREQEevToUeo2y5YtQ79+/TBt2jQAwLx58xAWFoYVK1ZgzZo11R4zERku1eMBIylTieYOVlgwuD1kMg4YRERUKPj36zh5+yEsTY2wdoQXbMxrd7P200QtLJ6WkZEBALC1tS1znZMnT2LKlCnFlvn5+WHPnj2lrq9UKqFUKrXPMzMzAQAqlQoqlUqn+IrW13U7qTGEPJiDdBhCHkWxLzgYjTMxqbBUGGH5254wlQt6lVdlvgup5RkcHIxdu3bh+vXrMDc3h4+PD7799lt4eHg8c7vt27fjq6++QmxsLJo3b45vv/0WAwYMqKGoiciQ7b1wHz8djwFQ2KzdwrGOyBFJj2QKC41Gg8mTJ6Nbt25o27ZtmeslJibC0bH43QwdHR2RmJhY6vrBwcGYO3duieWHDx+GhYVFhWINCwur0HZSYwh5MAfp0Pc8zj+UIeSfuwCAYW75iD77N57f8SVNFfkucnJyqiGSiiu6VPaFF15AQUEBZs6cCV9fX1y9ehWWlpalblN0qWxwcDAGDRqEzZs3w9/fH5GRkc8cV4iInudeNvD93sLeu0m9m6Ff2wYiRyRNkiksAgMDERUVhePHj1fp+wYFBRU7w5GZmQlXV1f4+vrC2tpap/dSqVQICwtD3759YWKiv6e+DCEP5iAdhpBHdEI6pq85DQAY+1JjfO6nn414lfkuis7mSgUvlSUiqUjNzsdP0UZQFmjQy8Men/bVzzGiJkiisJg0aRL27duHo0ePwsXF5ZnrOjk5ISkpqdiypKQkODmVPs2XQqGAQqEosdzExKTCfwRVZlspMYQ8mIN06Gse2coCTN5+BUqNDF0a18OM/q1gbKTfM3FX5LuQ+ndXHZfKEhE9T4Fag0+3XUKqUoZGtuZYNqwjjNisXSZRCwtBEPDRRx9h9+7dCA8PR5Mmz599xdvbG0eOHMHkyZO1y8LCwuDt7V2NkRKRIRIEATN2XcbNlGxYmwhY+lZ7vS8qDFF1XSoLsA/vacxBOgwhD0PI4b8Ho3HidipM5QKWv9UWFib6mU9N9eCJWlgEBgZi8+bN2Lt3L+rUqaP98bexsYG5uTkAYOTIkXB2dkZwcDAA4JNPPkHPnj2xaNEiDBw4EFu2bMG5c+ewbt060fIgIv3084lY/HbxPozlMoxuUQD7OiXPbpL4qutSWYB9eGVhDtJhCHnoaw6RD2T4+YYRAOC9ZhrEXjyJ2IsiB1VJ1d2DJ2phsXr1agBAr169ii3fsGEDRo0aBQCIi4uDXP7vEUQfHx9s3rwZX375JWbOnInmzZtjz549bMwjIp1ExqXhmwPXAADT/VrAMf2KyBFRaarzUlmAfXhPYw7SYQh56HMO1xKy8PkPpwFoMLZbI7TT3NbLPIrUVA+e6JdCPU94eHiJZUOHDsXQoUOrISIiqg0ePlIicFMkVGoBA9s1wCjvRvj9dxYWUlJTl8qyD690zEE6DCEPfcshLTsfgVsuIE+lQffmdpjq64FDB2/rXR6lqe4ePJ0Ki2vXrmHLli04duwY7ty5g5ycHNjb26Njx47w8/PD4MGDS/2BJiKSCrVGwOStF5CQkYem9pb47+B24D3wpIeXyhKRGArUGny85Tzupuaika0Flr/DZm1dlKtLMTIyEn369EHHjh1x/PhxdO3aFZMnT8a8efMwfPhwCIKAL774Ag0bNsS3335brBGOiEhKlh25gWM3HsDcxAhrhnuhjpl+H32SkmvXrmH27Nl4+eWX4e7ujgYNGqB9+/YICAjA5s2bdRobVq9ejYyMDPTq1QsNGjTQPrZu3apdJy4uDgkJCdrnRZfKrlu3Dp6entixYwcvlSUinSw8HK0dI9aO8EJdC1OxQ9Ir5TpjMXjwYEybNg07duxA3bp1y1zv5MmTWLZsGRYtWoSZM2dWVYxERFUiPDoZy/+8AQCY/2Zb3jW1ikRGRmL69Ok4fvw4unXrhq5du+KNN96Aubk5UlNTERUVhS+++AIfffQRpk+fjsmTJz/37DYvlSWimrbv0n2s/fs2AGDh0PZo1UC3PisqZ2Hxzz//lOv6Km9vb3h7e+vlNFxEZNji03MxeesFCALwXtdGeKPjsxuBqfx48ImI9N21hExM234JADC+R1MMat9Q5Ij0U7kKi/I2beTk5MDCwkLvG1uIyLDkF2jw4aZIpOeo0N7FBrNebS12SAaFB5+ISJ+l5+RjfGgEclVqdG9uh+n9Woodkt7S+U5Qr7zyCuLj40ssP3PmDDp06FAVMRERVan5B67h4t102JibYOW7naAwNhI7JIOiy8EnXdYnIqpuao2Aj7dcQFxqDlzqmeP7t9msXRk6FxZmZmZo3769toFOo9Fgzpw5eOmllzBgwIAqD5CIqDL2X0pAyIlYAMDitzzhaluxm55R+fDgExHpk0WHo3H0nxSYmcixdoQX6lmyWbsydC4s9u/fj6+//hpjxozBu+++i5deegk//PAD9u3bh6VLl1ZDiEREFXM75RE+31l4zezEXu54pZWjyBEZPh58IiJ9ceByAlaF3wIAfDu4Pdo0tBE5Iv1XoRvkBQYG4t69e/j2229hbGyM8PBw+Pj4VHVsREQVlpuvxoebIvFIWYAuTWzxWd8WYodUK+zfvx8rV67EmDFjsHfvXsTGxuLOnTvYt28ffH19xQ6PiAgAEJ2YhanbLwIAxnVvgtc7OIsckWHQubBIS0vD2LFjceTIEaxduxZ///03fH19sWDBAnz44YfVESMRkc5m/xqF64lZsLMyxYp3OsLYSOcTtFRBPPhERFKWkaPC+NBzyMlXw8e9Pj5ns3aV0Xmkbdu2LZKSknD+/HmMGzcOv/zyC3766Sd89dVXGDhwYHXESESkk+3n7mLbuXuQy4Dv3+4IB2szsUOqNdLS0jB48GCsXr0aa9euxVtvvQVfX1+sWrVK7NCIiKDWCPhk63nEPsyBc11zrHi3Ew88VSGdP8kJEybg6NGjaNKkiXbZsGHDcPHiReTn51dpcEREuopOzMJXe6MAAJ/2aQGfZnYiR1S78OATEUnZkrB/EB6dAoVxYbO2LZu1q5TOhcVXX30FubzkZi4uLggLC6uSoIiIKiJbWYCJmyKQp9KgRwt7BPZuJnZItQ4PPhGRVB2MSsCKv24CAP47uB3aOrNZu6qVq7CIi4vT6U1Lm2qQiKg6CYKAmbsv43ZKNpyszbB0WAfIORd5jePBJyKSohtJWfhsW2Gz9phuTfBGRxeRIzJM5SosXnjhBYwfPx5nz54tc52MjAz88MMPaNu2LXbu3FllARIRlcf/ztzF3gv3YSSXYcW7HXl6uwbx4BMRSVlGrgofhEYgO1+NF5vaImgAm7WrS7kKi6tXr8LS0hJ9+/aFk5MTBg4ciHHjxuGjjz7C8OHD0alTJzg4OGD9+vVYsGABPv744+qOm4hIKyo+A3N+uwIAmO7ngc6NbUWOqHbhwScikiqNRsCnWy8g5kE2GtqYYeW7nWDCZu1qU67pZuvXr4/Fixfjm2++wf79+3H8+HHcuXMHubm5sLOzw3vvvQc/Pz+0bdu2uuMlIiomK0+FSZsjkV+gwSstHTCue1OxQ6p1rl69im+++QZ9+/aFmZkZvLy80LBhQ5iZmSEtLQ1Xr17FlStX0KlTJyxYsIA3yiOiGrP0yA38eT35cbN2Z9S3UogdkkHT6T4W5ubmGDJkCIYMGVJd8RARlZsgCJix67J22sBFb3myr0IEPPhERFJ06Eoivj9yAwAw/412aOfCZu3qVqE7b1eVo0ePYuHChYiIiEBCQgJ2794Nf3//MtcPDw9H7969SyxPSEiAk5NTNUZKRFL0y6k72H8pAcZyGZa/2xF1LdhXISYefCIiqbiZ/G+z9iifxhjsxWbtmiDqRWbZ2dnw9PTEypUrddouOjoaCQkJ2oeDg0M1RUhEUnX5Xgbm7bsGAJjRvyU6NaonckRERCQFmXmFzdqPlAXo2sQWXwxsJXZItYaoZyz69++P/v3767ydg4MD6tatW/UBEZFeyMxTIXBzJPLVGvRt7Yj3X2ry/I2IiMjgaTQCpmy9gNsp2WhgY4aV77FZuyaJWlhUVIcOHaBUKtG2bVvMmTMH3bp1K3NdpVIJpVKpfZ6ZmQkAUKlUUKlUOu23aH1dt5MaQ8iDOUhHTechCAKmb7+EuNQcONc1Q7B/axQUFFTqPfld6H/uREQA8P2fN/DHtWSYGsuxZrgX7NisXaP0qrBo0KAB1qxZg86dO0OpVOLHH39Er169cPr0aXTq1KnUbYKDgzF37twSyw8fPgwLC4sKxWEoN3kyhDyYg3TUVB7HEmU4GGMEI5mAYS6P8H9/Vd1+a/N3kZOTUw2REBHVnLCrSVj6R2Gz9jf+beHpWlfcgGqhchcW33//fanLbWxs0KJFC3h7e1dZUGXx8PCAh4eH9rmPjw9u3bqFJUuWIDQ0tNRtgoKCMGXKFO3zzMxMuLq6wtfXF9bW1jrtX6VSISwsDH379oWJiUnFkpAAQ8iDOUhHTeZx5X4mpq47DUDA5/1aYrSPW5W8L7+Lf8/mSgkn+CCi8rqV8ghTtl4AAAR4u2FoZ1dxA6qlyl1YLFmypNTl6enpyMjIgI+PD3799VfY2tbsjam6dOmC48ePl/m6QqGAQlHyNJiJiUmF/4CozLZSYgh5MAfpqO48MvNU+GTbJajUAvq0csS4Hu6Qyap2atna/F1UNu/qOPhUNMHHmDFj8Oabb5Z7u+jo6GIHjjjBB5Fhy8pT4YON55ClLECXxrb4clBrsUOqtcpdWMTExJT52u3btzF8+HB8+eWXWLVqVZUEVl4XLlxAgwYNanSfRFSzBEFA0M7LuPP4fhXfDW1f5UUFVU51HHziBB9E9DwajYDPtl3ErZRsOFmbYcV7HdmsLaIq6bFo2rQp/vvf/2LMmDE6bffo0SPcvHlT+zwmJgYXLlyAra0tGjVqhKCgIMTHx2Pjxo0AgKVLl6JJkyZo06YN8vLy8OOPP+LPP//E4cOHqyINIpKoX07HYf/lwvtVrOD9KiRJSgefdJngg4j028q/buLw1SSYGsmxZoQXHOqYiR1SrVZlzduNGjVCYmKiTtucO3eu2PWwRb0QAQEBCAkJQUJCAuLi4rSv5+fn47PPPkN8fDwsLCzQvn17/PHHH6VeU0tEhiEqPgPzfrsKAPi8X0t05P0q9E5FDz7pqiITfHDmwOKYg3QYQh7VncNf0SlY/Mc/AIA5r7ZCGyfLatlXbf8udNmmygqLy5cvw81Nt0bKXr16QRCEMl8PCQkp9nz69OmYPn16RcIjIj2UlafCpMf3q3ilpQPGduf9KvRVRQ4+6aoiE3xw5sDSMQfpMIQ8qiOH5Fxg8WUjCIIM3Rw1sEy6iAMHLlb5fp5UW78LXWYNLHdhUdaMIRkZGYiIiMBnn32GgICAcu+YiOhZBEHAzN1RiH2Yg4Y2ZvhuqCf7KvRYRQ4+VYXnTfDBmQOLYw7SYQh5VFcOj5QFGLr2NHLV2fBqVBfrRneGqXH19VXU9u9Cl1kDy11Y1K1bt8xBXSaTYezYsZgxY0a5d0xE9Cz/O3MXv128DyO5DMvf7Yh6luyrkDKpHnx63gQfnDmwdMxBOgwhj6rMQRAEBG25hJsp2XC0VmD1CC9YmtfMTfBq63ehy/rlLiz++uuvUpdbW1ujefPmMDMzQ3JyMho2bFjunRMRleZaQibm/nYFADDNzwNebjU7jTXprjoOPnGCDyJ62qrwWzh4JREmRjKsHs5mbakpd2HRs2fPZ75+8eJFdOrUCWq1utJBEVHtla0sQODmSCgLNOjlYY8PujcVOyQqh+o4+MQJPojoSX9FJ+O7w9EAgLmvtUUnTuYhOVXWvE1EVFmCIODLPVG4/Xg+8sVvdYBczr4KfVAdB584wQcRFYl9kI1P/nceggC806UR3u3aSOyQqBS8gwgRScb2c/ew+3w8jOQyfP9OR9iyr4KIqNbLVhZgfGgEMvMK0LFRXcx5jXfWlioWFkQkCf8kZWHWr1EAgCl9W6BLE/ZVEBHVdoIgYPqOS4hOyoJ9HQXWDPeCwthI7LCoDOW+FOrSpUvPfD06OrrSwRBR7ZSTX4DATZHIU2nQvbkdJvZ0FzskIiKSgDV/38b+ywmFzdrvdYKjNZu1pazchUWHDh0gk8lKvd61aDnnmCeiipi99wpuJD+CQx0FlgxjX4U+4sEnIqpqf/+TggWHrgMAZr/aBp0b80y21JW7sIiJianOOIioltoZcQ/bI+5BLgOWvd0RdlY1Mx85VS0efCKiqnTnYTY+ftysPayzK95js7ZeKHdhIcYdU4nIsN1MzsKXewr7Kib3aQFv9/oiR0QVxYNPRFRVcvILm7UzclXo4FoXX/u34YEJPVHu5u0FCxYgNzdX+/z//u//oFQqtc+zsrLw4YcfVm10RGSwcvPVCNx0HrkqNbo1q4/A3s3EDokqwc3NrVwPIqJnKWrWvp6YBTsrBVYP78RmbT1S7sIiKCgIWVlZ2uf9+/dHfHy89nlOTg7Wrl1btdERkcGa8+sVRCcVDhxLh3WEEfsqDMaxY8cwfPhweHt7a8eJ0NBQHD9+XOTIiEjqfjh2G/suJcBYLsPq4Z3QwMZc7JBIB+UuLJ6+bvZZNy0iInqWXZH3sPXcXchkwPdvd4B9HfZVGIqdO3fCz88P5ubmOH/+vPbMdkZGBubPny9ydEQkZcdvPMB/fy9q1m6NF9isrXd4HwsiqlE3k7Pwxe7CvopPXmkOn2Z2IkdEVek///kP1qxZgx9++AEmJiba5d26dUNkZKSIkRGRlN1NzcGk/0VCIwBvdXbB8Bd56aQ+YmFBRDXmyb4KH/f6+Ojl5mKHRFUsOjoaPXr0KLHcxsYG6enpNR8QEUlebr4aH4RGID1HBU8XG3z9els2a+upcs8KBQA//vgjrKysAAAFBQUICQmBnV3h0cYn+y+IiEoz+9eof/sq3u7AvgoD5OTkhJs3b6Jx48bFlh8/fhxNmzYVJygikixBEPD5zku4lpAJOytTrBnhBTMTNmvrq3IXFo0aNcIPP/ygfe7k5ITQ0NAS6xARlWZnxD1sO1d4v4rv3+4Ahzq8e6ohGjduHD755BOsX78eMpkM9+/fx8mTJzF16lR89dVXYodHRBLz0/EY/HrxPozlMqx8l83a+q7chUVsbGyV7/zo0aNYuHAhIiIikJCQgN27d8Pf3/+Z24SHh2PKlCm4cuUKXF1d8eWXX2LUqFFVHhsRVZ0bSf/er+KTV1qwr8KAzZgxAxqNBq+88gpycnLQo0cPKBQKTJ06FR999JHY4RGRhJy4+QDzD1wDAHw5sBW6NuW9jPSdqD0W2dnZ8PT0xMqVK8u1fkxMDAYOHIjevXvjwoULmDx5MsaOHYtDhw5Vc6REVFE5+QX4cFMkclVqvNTMDpNe5v0qDJlMJsMXX3yB1NRUREVF4dSpU0hJScG8efOK3QuJiGq3u6k5CNxc2Kw9uJMLAnwaix0SVYFyn7HIzc3FkSNHMGjQIACF97V48gZ5RkZGmDdvHszMyn95Q//+/dG/f/9yr79mzRo0adIEixYtAgC0atUKx48fx5IlS+Dn51fu9yGimiEIAr7cE4UbyY9gX0eBJcPYV1FbmJqaonXr1gAApVKJxYsXY8GCBUhMTBQ5MiISW26+GuNDI5CWo0J7Fxt88wabtQ1Fuc9Y/Pzzz8VugLdixQqcOHEC58+fx/nz5/HLL79g9erV1RJkkZMnT6JPnz7Flvn5+eHkyZPVul8iqpjt5+5hV2Q85DJg+Tsdeb8KA6ZUKhEUFITOnTvDx8cHe/bsAQBs2LABTZo0wZIlS/Dpp5+KGyQRiU4QBMzcfRlXEzJR39IUa4azWduQlPuMxaZNmzB9+vRiyzZv3qyd5eOXX37BypUrq3XgSExMhKOjY7Fljo6OyMzMRG5uLszNSzb8KJXKYmdWMjMzAQAqlQoqlUqn/Retr+t2UmMIeTAH6Sgrj+uJWfhqb2FfxaevNIOXq7VkczX070KXbStq1qxZWLt2Lfr06YMTJ05g6NChGD16NE6dOoXFixdj6NChMDLiHw9Etd36/4vF7vPxMJLLsOLdTmhYl83ahqTchcXNmzfRrl077XMzMzPI5f+e8OjSpQsCAwOrNroqEBwcjLlz55ZYfvjwYVhYWFToPcPCwiobliQYQh7MQTqezCNPDSy6ZARlgQyt6mrg8ug6Dhy4LmJ05WOI30V55eTkVGqf27dvx8aNG/Haa68hKioK7du3R0FBAS5evMhLHIgIAHDiVvFmbW93NmsbmnIXFunp6cWO/KekpBR7XaPRFHu9Ojg5OSEpKanYsqSkJFhbW5d6tgIo7AWZMmWK9nlmZiZcXV3h6+sLa2trnfavUqkQFhaGvn37FrujrL4xhDyYg3Q8nYcgCJi87RKS85LgZK3AzxO9Uc/CVOwwn8lQvwtdFJ3Nrah79+7By8sLANC2bVsoFAp8+umnLCqICAAQn56LSZvPQ60R8GZHZ4xis7ZBKndh4eLigqioKHh4eJT6+qVLl+Di4lJlgZXG29sbBw4cKLYsLCwM3t7eZW6jUCigUJS8rtvExKTCf0BUZlspMYQ8mIN0FOUR8n8xOBCVBGO5DKuGe8HBxlLs0MrN0L4LXbepDLVaDVPTfwtIY2Nj7Q1VK4pTkhMZhjyVGuNDzyE1Ox9tna0x/812POhgoMpdWAwYMACzZs3CwIEDS8z8lJubi7lz52LgwIE67fzRo0e4efOm9nlMTAwuXLgAW1tbNGrUCEFBQYiPj8fGjRsBABMmTMCKFSswffp0jBkzBn/++Se2bduG/fv367RfIqoekXFp+Obxae6ZA1qhU6N6IkdENUUQBIwaNUp7ICcvLw8TJkyApWXxwnLXrl3lfs+iKcnHjBmDN99887nrF01JPmHCBGzatAlHjhzB2LFj0aBBA84cSCQSQQBm/XoVUfGZsGWztsErd2Exc+ZMbNu2DR4eHpg0aRJatGgBAIiOjsaKFStQUFCAmTNn6rTzc+fOoXfv3trnRZcsBQQEICQkBAkJCYiLi9O+3qRJE+zfvx+ffvopli1bBhcXF/z4448cMIgkIDU7H5M2RUKlFjCgnRNGd2ssdkhUgwICAoo9Hz58eKXfk1OSE+m/Y4ky7I5NeNys3REu9SrW30r6odyFhaOjI06cOIGJEydixowZEAQBQOHNkPr27YtVq1aVmLHpeXr16qV9n9KEhISUus358+d12g8RVS+NAHy24zLuZ+ShiZ0lvh3cnqe5a5kNGzaIHUKZU5JPnjy5zG04c2BxzEE6DCGPEzeSsTu2cKKfz/1a4IVGNnqZjyF8FzU1a2C5Cwug8IzBwYMHkZqaqr2EqVmzZrC1tdUtQiIyKIfuyXH83kOYmcixengn1DHT/z4F0j8VmZKcMweWjjlIh77mkaYEvrtkBA1k8LLTwCHtCg4cuCJ2WJWir9/Fk6p71kCdCositra26NKlS0U2JSIDc/TGAxy6V3h2IvjNdmjppNtsa0Ri4syBxTEH6dDnPJQqNd756SweFWTC2ULAunG9YG1h9vwNJUqfv4siNTVrYIUKCyIiALiXloPPtl+GABne7eKCNzpW78xwRM9SkSnJOXNg6ZiDdOhbHoIgYOaeq7gcn4m65iZ43yMX1hZmepVDWfTtuyhNdc8aKH/+KkREJeWp1Jj4SyTSc1VoZClgZv+WYodEtZy3tzeOHDlSbNnzpiQnoqr1y6k72B5xD3IZsHRYe9TX3xMVVAEsLIhIZ4IgYNbeKFyOz0A9CxOM9lBDYcyfE6pajx49woULF3DhwgUA/05JXjRbYFBQEEaOHKldf8KECbh9+zamT5+O69evY9WqVdi2bRs+/fRTMcInqnXOxKRi7m9XAQAz+rdEN95Zu9bhXwJEpLMtZ+9i27nHR6Teag/bkleSEFXauXPn0LFjR3Ts2BFA4ZTkHTt2xKxZswCgzCnJw8LC4OnpiUWLFnFKcqIakpCRiw83RaBAI2BQ+wYY172p2CGRCNhjQUQ6OR+Xhtl7C2f2mOrnAR/3+jgQLXJQZJA4JTmRfshTqTHhl0g8eJSPlk51sGAIpxyvrXjGgojKLTkrDxN/iUS+WgO/No6Y2NNd7JCIiEhEgiBg9t4ruHg3HTbmJlg3ojMsTHncurZiYUFE5ZJfoEHgpkgkZubB3d4S3w315BEpIqJabtPpOGw9dxdyGbD8nY5oVJ931q7NWFgQUbl8s/8qzsamwUphjHUjO/MmeEREtdy52FTM/a3w0tjp/VqiRwt7kSMisbGwIKLn2nbuLn4+eQcAsGRYB7jbW4kcERERiSkxIw8TfomESi1gYLsGGN+DzdrEwoKIniMyLg1f7o4CAHzySnP0be0ockRERCQmZYEaEzdF4MEjJTwc2axN/2JhQURlSsrMw4TQCOSrNfBt7YhPXmkudkhERCSyOb9ewfm4dFibGWPtCC9YKtisTYVYWBBRqfJUanwQGoHkLCVaOFph8bAOkMt5RIqIqDbbfDoO/ztzFzIZ8P07HdHYzlLskEhCWFgQUQmCICBo12Xt9IE/jOwMKx6RIiKq1SLupGH2r4WXxk719UAvDweRIyKpYWFBRCWs/vsWdp+Ph5FchlXvdYJbfR6RIiKqzZIy8zDxlwio1AL6t3XCh714HyMqiYUFERVz+EoiFh4qvJX2nFdbo1szO5EjIiIiMeUXaDDxl8JLY5s7WGEh72NEZWBhQURaV+9nYvLWCxAEYPiLjTDCu7HYIRERkcjm/nYFkXHpqGNWeB8jXhpLZWFhQUQACk9zv//zWeTkq+HjXh+zX20jdkhERCSyLWfisOl0XGGz9tsd0YTN2vQMkigsVq5cicaNG8PMzAxdu3bFmTNnylw3JCQEMpms2MPMzKwGoyUyPDn5BRj78zkkZOTB3d4Sq9/zgomRJH4eiIhIJJFxaZi1t/DO2lP6tEDvlmzWpmcT/S+HrVu3YsqUKZg9ezYiIyPh6ekJPz8/JCcnl7mNtbU1EhIStI87d+7UYMREhkWjEfDp1gu4HJ8BW0tTrB/1AmwsTMQOi4iIRJScVdisna/WwK+NIwJ7NxM7JNIDohcWixcvxrhx4zB69Gi0bt0aa9asgYWFBdavX1/mNjKZDE5OTtqHoyPvBExUUd8cuIZDV5JgaiTHuhFenAGKiKiWyy/QIHBTJJIylWjmYIVFb/E+RlQ+onbf5OfnIyIiAkFBQdplcrkcffr0wcmTJ8vc7tGjR3Bzc4NGo0GnTp0wf/58tGlT+vXgSqUSSqVS+zwzMxMAoFKpoFKpdIq3aH1dt5MaQ8iDOVSNkJN38NPxGADAf99sA0/nOrXy34Uh5ABULg99z52Iqs68fVdxNjYNdRTGWDfCi83aVG6i/pfy4MEDqNXqEmccHB0dcf369VK38fDwwPr169G+fXtkZGTgu+++g4+PD65cuQIXF5cS6wcHB2Pu3Lkllh8+fBgWFhYVijssLKxC20mNIeTBHCru4kMZNvwjByDDa43UMLp3Hgfuna/w+/G7kI6K5JGTk1MNkRCRvtl29i5CTxVeYr5kWAc0tbcSOSLSJ3pXgnp7e8Pb21v73MfHB61atcLatWsxb968EusHBQVhypQp2ueZmZlwdXWFr68vrK2tddq3SqVCWFgY+vbtCxMT/b0G3RDyYA6Vc+5OGjaFRECABu92ccGcQa0qPCc5vwvpqEweRWdziaj2unA3HV/uKbyz9qd9WqBPa15qTroRtbCws7ODkZERkpKSii1PSkqCk5NTud7DxMQEHTt2xM2bN0t9XaFQQKFQlLpdRf+AqMy2UmIIeTAH3UUnZmH8L+ehLNCgTysHfP16OxhXwQxQ/C6koyJ5GELeRFRxKVlKTAgtbNbu29oRH73MZm3SnajN26ampvDy8sKRI0e0yzQaDY4cOVLsrMSzqNVqXL58GQ0aNKiuMIkMxr20HIxcfxqZeQXwcquH5e90qpKigoiI9JdKrUHg5kgkZuahqb0lFr/lyWZtqhDR/6KYMmUKfvjhB/z888+4du0aJk6ciOzsbIwePRoAMHLkyGLN3V9//TUOHz6M27dvIzIyEsOHD8edO3cwduxYsVIg0gsPHykxcv0ZJGUq0dzBCj8FdIa5qZHYYRE9E+9zRFT9vtl/DWdiUmGlMMa6EZ1Rx4xnMKliRO+xGDZsGFJSUjBr1iwkJiaiQ4cOOHjwoLahOy4uDnL5v/VPWloaxo0bh8TERNSrVw9eXl44ceIEWrduLVYKRJKXmafCyPVncDslGw1tzLDx/S6oa2EqdlhEz1R0n6M1a9aga9euWLp0Kfz8/BAdHQ0Hh9Jv1GVtbY3o6Gjt84r2DhHVFjsi7iHkRCyAwmbtZg5s1qaKE72wAIBJkyZh0qRJpb4WHh5e7PmSJUuwZMmSGoiKyDDk5qvxfshZXLmfifqWpggd2xUNbMzFDovouZ68zxEArFmzBvv378f69esxY8aMUrcpus8RET3f5XsZmLn7MgDgk1eaoy+btamSJFFYEFH1UBaoMf6XiML5yM2MsfH9LnDn1IGkB2riPkcA73X0NOYgHdWdx8PsfHwQeg75BRq87GGPD3s0rvJ98buQjpq6zxELCyIDlV+gwYe/ROLoPykwNzFCyOgX0KahjdhhEZVLTdznCOC9jsrCHKSjOvJQa4BV1+RIyJTDwUyAr3UCDh5MqPL9FOF3IR3VfZ8jFhZEBkil1mDS5kgcuZ4MhbEcPwV0hpebrdhhEVUrXe9zBPBeR09jDtJRnXl8c+A6bmbGwdLUCD+P61ptfRX8LqSjpu5zxMKCyMCo1Bp8suU8Dl9NgqmxHD+M7AyfZnZih0Wkk5q4zxHAex2VhTlIR1Xnsfv8PYScjAMALHqrA1o516uy9y4LvwvpqO77HIk+3SwRVZ38gsIzFQcuJ8LUSI61I7zQo4W92GER6Yz3OSKqelHxGZixs7BZe1LvZujXlhMdUNXiGQsiA5GnUuPDTZH483oyTI3lWDO8E3p7lD4lJ5E+mDJlCgICAtC5c2d06dIFS5cuLXGfI2dnZwQHBwMovM/Riy++iGbNmiE9PR0LFy7kfY6IHkvNzsf40AgoCzTo7WGPT/u2EDskMkAsLIgMQE5+AcaHRuDYjQcwM5Fj3YjOPFNBeo/3OSKqGgWP++7i03PRuL4Flr7dEUa8szZVAxYWRHouPScfY0LOIjIuHRamRvgp4AV4u9cXOyyiKsH7HBFV3n9/v44Ttx7CwtQI60Z2ho25fvcJkHSxsCDSY0mZeRj50xlEJ2XB2swYG0a/wNmfiIhIa++FePx4PAYA8N1QT7RwrCNyRGTIWFgQ6albKY8wasMZ3E3NhUMdBULf7woPJw4YRERU6Mr9DHy+8xIA4MNe7hjQjhMZUPViYUGkh87GpmLcxnNIz1HBrb4Ffnm/K1xtK3YzLyIiMjxpj5u181Qa9Gxhj898PcQOiWoBFhZEembfpfuYsu0i8gs06OBaFz8GdIadVcl5+ImIqHYqUGvw0f/O415aLhrZWuB7NmtTDWFhQaQnNBoBy47cwLIjNwAAfm0csXRYR5ibGokcGRERScnCQ9E4fvMBzE2MsG6kF2ws2KxNNYOFBZEeyFYW4LNtF3HwSiIAYEy3JvhiYCsegSIiomJ+vXgfa4/eBgAsHNoeLZ2sRY6IahMWFkQSF/sgGxN+icD1xCyYGMnwjX87vPWCq9hhERGRxFxLyMT0HRcBABN6umNQ+4YiR0S1DQsLIgk7GJWAadsvIUtZADsrBdaO6MTpZImIqIT0nHx8EHoOeSoNuje3wzQ/NmtTzWNhQSRBygI1FhyMxk+P5x5/oXE9LH+nE5xszESOjIiIpEatEfDR/87jbmouXG3N2axNomFhQSQxN5Oz8PH/LuBqQiYA4IMeTTHNzwMmRnKRIyMiIilaeCgax248btYe0Rn1LE3FDolqKUn8pbJy5Uo0btwYZmZm6Nq1K86cOfPM9bdv346WLVvCzMwM7dq1w4EDB2ooUqLqo9EI2HgyFgO/P46rCZmoZ2GCdSO8MHNAKxYVRERUqv2XErDm71sAgG+HtEerBmzWJvGI/tfK1q1bMWXKFMyePRuRkZHw9PSEn58fkpOTS13/xIkTeOedd/D+++/j/Pnz8Pf3h7+/P6Kiomo4cqKqE/sgG+/8cAqz9l6BsqDw+thDk3vAt42T2KEREZFEXU/MxNTthc3aH/Roitc82axN4hK9sFi8eDHGjRuH0aNHo3Xr1lizZg0sLCywfv36UtdftmwZ+vXrh2nTpqFVq1aYN28eOnXqhBUrVtRw5ESVp9YAPx6PRb9lR3E6JhXmJkaY/Wpr/Dy6Cxys2U9BRESly8hRYXxoBHJVarzUzA7T2axNEiBqj0V+fj4iIiIQFBSkXSaXy9GnTx+cPHmy1G1OnjyJKVOmFFvm5+eHPXv2lLq+UqmEUqnUPs/MLLxuXaVSQaVS6RTvzoi7uJwsQ17kXShMTGAkl8FYLoOxkQxGchlMjeQwlstgYiR//JDBxFgOUyM5TI3lUDx+GMtlkMnEa6oqylvX/KXEEHI49k8yFlwyQmLuPwAAn6a2mPd6azSytYBaXQC1WuQAy8kQvgtDyAGoXB76njtRbaLWCPh4y3nceZgDl3rmWP5ORxjzklmSAFELiwcPHkCtVsPR0bHYckdHR1y/fr3UbRITE0tdPzExsdT1g4ODMXfu3BLLDx8+DAsLC53inXvGCLlqI2y6dU2n7Z4mgwATObQPUzlgavT4f+UCFEYofMgBhTFgZiTAzAgwMwLMjQBzYwHmRoCFMWBuXLhdReqUsLCwSuUhBfqYQ0ousO+uHBceygHIYGks4DU3DbraJyPqVDL09aI+ffwunmYIOQAVyyMnJ6caIiGi6rA4LBp//5MCMxM51o7wYrM2SYbBzwoVFBRU7AxHZmYmXF1d4evrC2tr3RqcDmScR9z9JNStVx8CgAKNgAKNALVGgEotoECtgUotQKXWoEBT+L/5BRrkP15eRIAM+RogX1PaXnSvEEyN5ahrboK65iaoZ2kCWwtT2Fqaor6lKWytTGFnaQr7OgrYWZnCoY4CRtAgLCwMffv2hYmJic77kwKVSqV3OTx4pMSKv25j66V7KNAIkMuAbo4aLBjRA3bWuhW5UqKP38XTDCEHoHJ5FJ3NJSJp+/1yAlb+9bhZe3B7tGloI3JERP8StbCws7ODkZERkpKSii1PSkqCk1PpTatOTk46ra9QKKBQKEosNzEx0XngXfFORxw4cAADBryg87YajYB8tQZKlQbKAjXyVBrkFaiRp1IjN1+NHJUaeflqZOerkZtfgOx8NbKVBXikLEC2sgBZeUUPFbLyCpCRq0JGrgoFGgH5BRokZymRnKV8fiAArM2MYSEzwvaUS2hY1xxONuZoaGOGhnXN0bCuOZzrmsPc1Ein/MRSke+xpiVk5OKHozH435k45KoKr2/q2cIen/Vphpjzx2BnbSH5HMpDH76L5zGEHICK5WEIeRMZun+SsvDZ42btsS81wesdnEWOiKg4UQsLU1NTeHl54ciRI/D39wcAaDQaHDlyBJMmTSp1G29vbxw5cgSTJ0/WLgsLC4O3t3cNRFxxcrkMZnIjmJkYAaiaAVwQBOTkq5GWk4/0HBXScvKRmv3v48GjfDx4pMTDR0qkPFIiOVMJZYEGmXkFyIQMiTcflvnedlamcK5nAZd65mhkawHXehZoZGsBt/oWaFjXnDfeKYdrCZkI+b9Y7Dp/T3vGqoNrXXzeryW83etDpVIh5rzIQRIRkV7IyFXhg43nkJOvho97fczo31LskIhKEP1SqClTpiAgIACdO3dGly5dsHTpUmRnZ2P06NEAgJEjR8LZ2RnBwcEAgE8++QQ9e/bEokWLMHDgQGzZsgXnzp3DunXrxExDFDKZDJYKY1gqjOFS7/nrC4KALGUB4h8+wm9/HINbq/ZIeaTC/Yw8JGbk4X56LuLTcpGlLHhclOTj4t30Eu9jYiSDa73CIqOxnSWaPPFoaGMOeS0uOvJUaoRdTULoqTs4E5OqXd61iS0mvdwMLzWzE7Vxn4iI9I9aI2DylvOIfZgD57rmWPFuJzZrkySJXlgMGzYMKSkpmDVrFhITE9GhQwccPHhQ26AdFxcHufzffzw+Pj7YvHkzvvzyS8ycORPNmzfHnj170LZtW7FS0BsymQzWZiYwd7CCR10BAzo6l3r5Q0auCvfScnA3Nffx/+bgTmoO4lJzcC81F/lqDW4/yMbtB9lAdEqxbU2N5WhS3xJN7R8/7Kzg7mCFpvaWsDYzzEst1BoBkXFp2H0+Hvsu3kdmXgEAwEguQ782ThjzUmN4udmKHCUREemrpX/8g7+iU6AwLmzWtmWzNkmU6IUFAEyaNKnMS5/Cw8NLLBs6dCiGDh1azVHVXjbmJrAxtym1IUytEZCYmYc7D7IR8zAbsQ+yEfMgBzEPHiEuNQf5BRpEJ2UhOimrxLZ2Vgo0tbeE++OCo4ldYfHhamuhd3eWzlYW4HTMQ4RdTULY1WQ8ePRvf0sDGzMM8XLBe13d4GTDe1EQVcbKlSuxcOFCJCYmwtPTE8uXL0eXLl3KXH/79u346quvEBsbi+bNm+Pbb7/FgAEDajBioqp1+GoSlv95EwDw38Ht0NaZzdokXZIoLEh/GMllcH7c4O3TzK7YawVqDeLTc3E7JRu3Uh4VntVIeYTbKdlIzlLiwaPCx5OXCBW9p2s9czS2s0Tj+pZwq194mVUjW0u41DN/3JcirtTsfFy4m4bzcek4dfshzselo0Dz70xfdcyM0be1I4Z0csGLTevX6svBiKrK1q1bMWXKFKxZswZdu3bF0qVL4efnh+joaDg4OJRY/8SJE3jnnXcQHByMQYMGYfPmzfD390dkZCTPapNeis8GVu4snIR8TLcmeKOji8gRET0bCwuqMsZGcrjVt4RbfUv0bll80M/KUyHmQTZupzwuNh7//5gH2chVqRH7MAexD3MApJR4X4c6CjjXKyxmGtY1h5O1GewsjXE7E7jzMAdO9SxhaWpU6d4FlVqDxIw83E3Lwb20XNxKeYQbSY/wT1IW7qXllli/ka0FerSwg18bJ3RtUh+mxvp11oVI6hYvXoxx48Zpe+7WrFmD/fv3Y/369ZgxY0aJ9ZctW4Z+/fph2rRpAIB58+YhLCwMK1aswJo1a2o0dqLKUBaosfLPW1h52QhqQY0Xm9pi5gA2a5P0sbCgGlHHzATtXeqivUvdYssFQUBSphK3HzzCnYc5iH18eVVcai7iHmYjO1+tnUr3fFz6U+9qjGVXjgMo7O2weXwvjzpmxrAwNYaFqREUJkYwlsu0s1hpNALUgoA8lRo5j6f0Tc9V4eGjfGTkPvvOw+72lujgWg+dG9dDN3c7NKqvv/eeIJK6/Px8REREICgoSLtMLpejT58+OHnyZKnbnDx5sth9iwDAz88Pe/bsKXM/SqUSSuW/lzIW3c9DpVLpdDfy4zcfYt+l+4iPl+PorsvFegP1iUajYQ4SEHEnDbcf5ACQ4SV3Wywa2h6CRg2VRi12aDop+jeky78lKTKEPCqTgy7bsLAgUclkMjjZmMHJxgw+7sVfEwQBqdn5iH88W1V8ei7up+chKTMPCRm5uJOUhhyNEXJVhTciTMlSIqWc9/Ioi6mxHC51zeFczxyN61uihaMVmjvWQSsna9hYGGbzOZEUPXjwAGq1WjuRRxFHR0dcv3691G0SExNLXT8xMbHM/QQHB2Pu3Lkllh8+fBgWFuU/eBCeIMPuWCMAciA5odzbSRNzkII6JgLebKxBx/rJOPX3H2KHUylhYWFih1AlDCGPiuSQk5NT7nVZWJBkyWQy1LdSoL6VosSZDpVK9fhmhX7I18iQllN4xiEjR4UsZQFy89XIzi9AfoFGe2d0ADCSA3KZDGYmRrBUGMHC1BjWZiawr2OK+pYK2JibsD+CqBYJCgoqdpYjMzMTrq6u8PX1hbW1dbnfx+VeBtxupODmzRto1qw5jPT0SLlao2EOEmCpMEb/1nY4czwcffv21dsbWKpUKoSFhel1DoBh5FGZHIrO5JYHCwvSe7rcy4OI9IOdnR2MjIyQlJRUbHlSUhKcnJxK3cbJyUmn9QFAoVBAoVCUWK7r3cu9mtihvYsNDuT+gwG9m+n1Hx/MQRqKLj/R9b9FKTKEHADDyKMiOeiyvn6W8kREZNBMTU3h5eWFI0eOaJdpNBocOXIE3t7epW7j7e1dbH2g8LR/WesTEVHV4hkLIiKSpClTpiAgIACdO3dGly5dsHTpUmRnZ2tniRo5ciScnZ0RHBwMAPjkk0/Qs2dPLFq0CAMHDsSWLVtw7tw5rFu3Tsw0iIhqDRYWREQkScOGDUNKSgpmzZqFxMREdOjQAQcPHtQ2aMfFxRWb9cfHxwebN2/Gl19+iZkzZ6J58+bYs2cP72FBRFRDWFgQEZFkTZo0CZMmTSr1tfDw8BLLhg4diqFDh1ZzVEREVBr2WBARERERUaWxsCAiIiIiokqrdZdCCULh/Qx0mZO3iEqlQk5ODjIzM/V6ujFDyIM5SIch5GEIOQCVy6PoN7HoN7K2qu1jBHOQDkPIwxByAAwjj5oaH2pdYZGVlQUAcHV1FTkSIiLpycrKgo2NjdhhiIZjBBFR6cozPsiEWnZ4SqPR4P79+6hTpw5kMt3usFx0R9a7d+/qdEdWqTGEPJiDdBhCHoaQA1C5PARBQFZWFho2bFhspqXapraPEcxBOgwhD0PIATCMPGpqfKh1ZyzkcjlcXFwq9R7W1tZ6+x/WkwwhD+YgHYaQhyHkAFQ8j9p8pqIIx4hCzEE6DCEPQ8gBMIw8qnt8qL2HpYiIiIiIqMqwsCAiIiIiokpjYaEDhUKB2bNnQ6FQiB1KpRhCHsxBOgwhD0PIATCcPPSVIXz+zEE6DCEPQ8gBMIw8aiqHWte8TUREREREVY9nLIiIiIiIqNJYWBARERERUaWxsCAiIiIiokpjYVFBr732Gho1agQzMzM0aNAAI0aMwP3798UOSyexsbF4//330aRJE5ibm8Pd3R2zZ89Gfn6+2KHp5JtvvoGPjw8sLCxQt25dscMpt5UrV6Jx48YwMzND165dcebMGbFD0snRo0fx6quvomHDhpDJZNizZ4/YIeksODgYL7zwAurUqQMHBwf4+/sjOjpa7LB0snr1arRv3147N7m3tzd+//13scOq9fR9jDCU8QHQzzGC44P4DGF8AGp+jGBhUUG9e/fGtm3bEB0djZ07d+LWrVsYMmSI2GHp5Pr169BoNFi7di2uXLmCJUuWYM2aNZg5c6bYoekkPz8fQ4cOxcSJE8UOpdy2bt2KKVOmYPbs2YiMjISnpyf8/PyQnJwsdmjllp2dDU9PT6xcuVLsUCrs77//RmBgIE6dOoWwsDCoVCr4+voiOztb7NDKzcXFBf/9738RERGBc+fO4eWXX8brr7+OK1euiB1arabvY4ShjA+A/o0RHB+kwRDGB0CEMUKgKrF3715BJpMJ+fn5YodSKQsWLBCaNGkidhgVsmHDBsHGxkbsMMqlS5cuQmBgoPa5Wq0WGjZsKAQHB4sYVcUBEHbv3i12GJWWnJwsABD+/vtvsUOplHr16gk//vij2GHQEwxhjNDn8UEQ9GeM4PggTYYyPghC9Y4RPGNRBVJTU7Fp0yb4+PjAxMRE7HAqJSMjA7a2tmKHYdDy8/MRERGBPn36aJfJ5XL06dMHJ0+eFDEyysjIAAC9/TegVquxZcsWZGdnw9vbW+xw6DFDGSM4PlQ/jg/Spe/jA1AzYwQLi0r4/PPPYWlpifr16yMuLg579+4VO6RKuXnzJpYvX47x48eLHYpBe/DgAdRqNRwdHYstd3R0RGJiokhRkUajweTJk9GtWze0bdtW7HB0cvnyZVhZWUGhUGDChAnYvXs3WrduLXZYtZ4hjREcH2oGxwdp0ufxAajZMYKFxRNmzJgBmUz2zMf169e160+bNg3nz5/H4cOHYWRkhJEjR0KQwP0Gdc0DAOLj49GvXz8MHToU48aNEynyf1UkB6LKCAwMRFRUFLZs2SJ2KDrz8PDAhQsXcPr0aUycOBEBAQG4evWq2GEZHEMYIwxhfAA4RlDN0ufxAajZMYJ33n5CSkoKHj58+Mx1mjZtClNT0xLL7927B1dXV5w4cUL0SxB0zeP+/fvo1asXXnzxRYSEhEAuF7/erMh3ERISgsmTJyM9Pb2ao6uc/Px8WFhYYMeOHfD399cuDwgIQHp6ul4e1ZTJZNi9e3exfPTJpEmTsHfvXhw9ehRNmjQRO5xK69OnD9zd3bF27VqxQzEohjBGGML4ABjuGMHxQXoMbXwAqneMMK7yd9Rj9vb2sLe3r9C2Go0GAKBUKqsypArRJY/4+Hj07t0bXl5e2LBhg2QGjcp8F1JnamoKLy8vHDlyRPtDq9FocOTIEUyaNEnc4GoZQRDw0UcfYffu3QgPDzeYQUOj0Ujit8jQGMIYYQjjA2C4YwTHB+kw1PEBqN4xgoVFBZw+fRpnz57FSy+9hHr16uHWrVv46quv4O7uLvrZCl3Ex8ejV69ecHNzw3fffYeUlBTta05OTiJGppu4uDikpqYiLi4OarUaFy5cAAA0a9YMVlZW4gZXhilTpiAgIACdO3dGly5dsHTpUmRnZ2P06NFih1Zujx49ws2bN7XPY2JicOHCBdja2qJRo0YiRlZ+gYGB2Lx5M/bu3Ys6depor2G2sbGBubm5yNGVT1BQEPr3749GjRohKysLmzdvRnh4OA4dOiR2aLWWIYwRhjI+APo3RnB8kAZDGB8AEcaIaplrysBdunRJ6N27t2BraysoFAqhcePGwoQJE4R79+6JHZpONmzYIAAo9aFPAgICSs3hr7/+Eju0Z1q+fLnQqFEjwdTUVOjSpYtw6tQpsUPSyV9//VXq5x4QECB2aOVW1n//GzZsEDu0chszZozg5uYmmJqaCvb29sIrr7wiHD58WOywajVDGCMMZXwQBP0cIzg+iM8QxgdBqPkxgj0WRERERERUadK5YJKIiIiIiPQWCwsiIiIiIqo0FhZERERERFRpLCyIiIiIiKjSWFgQEREREVGlsbAgIiIiIqJKY2FBRERERESVxsKCiIiIiIgqjYUFERERERFVGgsLIiIiIiKqNBYWRERERERUaSwsiGpYSkoKnJycMH/+fO2yEydOwNTUFEeOHBExMiIiEhPHB9J3MkEQBLGDIKptDhw4AH9/f5w4cQIeHh7o0KEDXn/9dSxevFjs0IiISEQcH0ifsbAgEklgYCD++OMPdO7cGZcvX8bZs2ehUCjEDouIiETG8YH0FQsLIpHk5uaibdu2uHv3LiIiItCuXTuxQyIiIgng+ED6ij0WRCK5desW7t+/D41Gg9jYWLHDISIiieD4QPqKZyyIRJCfn48uXbqgQ4cO8PDwwNKlS3H58mU4ODiIHRoREYmI4wPpMxYWRCKYNm0aduzYgYsXL8LKygo9e/aEjY0N9u3bJ3ZoREQkIo4PpM94KRRRDQsPD8fSpUsRGhoKa2tryOVyhIaG4tixY1i9erXY4RERkUg4PpC+4xkLIiIiIiKqNJ6xICIiIiKiSmNhQURERERElcbCgoiIiIiIKo2FBRERERERVRoLCyIiIiIiqjQWFkREREREVGksLIiIiIiIqNJYWBARERERUaWxsCAiIiIiokpjYUFERERERJXGwoKIiIiIiCqNhQUREREREVXa/wOOeD9IAv5xpQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gelu, relu = GELU(), nn.ReLU()\n",
    "\n",
    "# Some sample data\n",
    "x = torch.linspace(-3,3,100)\n",
    "y_gelu, y_relu = gelu(x), relu(x)\n",
    "\n",
    "plt.figure(figsize=(8,3))\n",
    "for i, (y,label) in enumerate(zip([y_gelu,y_relu],['GELU',\"ReLU\"]),1):\n",
    "    plt.subplot(1,2,i)\n",
    "    plt.plot(x,y)\n",
    "    plt.title(f\"{label} activation function\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(f\"{label} (x)\")\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self,cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"],4* cfg[\"emb_dim\"]), ## Expansion\n",
    "            GELU(),  ## Activation\n",
    "            nn.Linear(4*cfg[\"emb_dim\"],cfg[\"emb_dim\"]), ## Contraction\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(GPT_CONFIG_124M[\"emb_dim\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 768])\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "ffn = FeedForward(GPT_CONFIG_124M)\n",
    "x = torch.rand(2,3,768) #A\n",
    "out = ffn(x)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT ARCHITECTURE PART 4: SHORTCUT CONNECTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Let us see how we can add shortcut connections to the forward method:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "class ExampleDeepNeuralNetwork(nn.Module):\n",
    "    def __init__(self,layer_sizes,use_shortcut):\n",
    "        super().__init__()\n",
    "        self.use_shortcut = use_shortcut\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                nn.Sequential(nn.Linear(layer_sizes[0],layer_sizes[1]),GELU()),\n",
    "                nn.Sequential(nn.Linear(layer_sizes[1],layer_sizes[2]),GELU()),\n",
    "                nn.Sequential(nn.Linear(layer_sizes[2],layer_sizes[3]),GELU()),\n",
    "                nn.Sequential(nn.Linear(layer_sizes[3],layer_sizes[4]),GELU()),\n",
    "                nn.Sequential(nn.Linear(layer_sizes[4],layer_sizes[5]),GELU()),\n",
    "\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        for layer in self.layers:\n",
    "            # Compute the output of the current layer\n",
    "            layer_output  = layer(x)\n",
    "            # Check if shortcut can be applied\n",
    "            if self.use_shortcut and x.shape == layer_output.shape:\n",
    "                x = x + layer_output\n",
    "            else:\n",
    "                x = layer_output\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "layer_sizes = [3,3,3,3,3,1]\n",
    "sample_input = torch.tensor([[1.,0.,-1.]])\n",
    "torch.manual_seed(123) # specify random seed for the initial weights \n",
    "model_without_shortcut = ExampleDeepNeuralNetwork(\n",
    "    layer_sizes,use_shortcut=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Next, we implement a function that computes the gradients in the model's backward pass:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def print_gradients(model,x):\n",
    "    # Forward pass\n",
    "    output = model(x)\n",
    "    target = torch.tensor([[0.]])\n",
    "\n",
    "    # Calcuate loss based on how close the target  and output are\n",
    "    loss = nn.MSELoss()\n",
    "    loss = loss(output,target)\n",
    "\n",
    "    # Backward pass to calculate the gradients\n",
    "    loss.backward()\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if \"weight\" in name:\n",
    "            # Print the mean absolute gradient of the weights\n",
    "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.00020173590746708214\n",
      "layers.1.0.weight has gradient mean of 0.0001201116101583466\n",
      "layers.2.0.weight has gradient mean of 0.0007152042235247791\n",
      "layers.3.0.weight has gradient mean of 0.0013988739810883999\n",
      "layers.4.0.weight has gradient mean of 0.00504964729771018\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print_gradients(model_without_shortcut,sample_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Let's now instantiate a model with skip connections and see how it comparees:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.22169791162014008\n",
      "layers.1.0.weight has gradient mean of 0.20694102346897125\n",
      "layers.2.0.weight has gradient mean of 0.32896995544433594\n",
      "layers.3.0.weight has gradient mean of 0.2665732204914093\n",
      "layers.4.0.weight has gradient mean of 1.3258541822433472\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model_without_shortcut = ExampleDeepNeuralNetwork(\n",
    "    layer_sizes,use_shortcut=True \n",
    ")\n",
    "print_gradients(model_without_shortcut,sample_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT ARCHITECTURE  PART 5: CODING ATTENTION AND LINEAR LAYERS IN A TRANSFORMER BLOCK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,      # Vocabulary size\n",
    "    \"context_length\": 1024,   # Context length\n",
    "    \"emb_dim\": 768,           # Embedding dimension\n",
    "    \"n_heads\": 12,            # Number of attention heads\n",
    "    \"n_layers\": 12,           # Number of layers\n",
    "    \"drop_rate\": 0.1,         # Dropout rate\n",
    "    \"qkv_bias\": False         # Query-Key-Value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THE BUILDING BLOCKS: LAYER NORMALIZATION, GELU AND FEED-FORWARD NEURALNETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self,emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self,x):\n",
    "        mean = x.mean(dim=-1,keepdim=True)\n",
    "        var = x.var(dim=-1,keepdim=True,unbiased=False)\n",
    "        norm_x = (x - mean)/ torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift\n",
    "\n",
    "\n",
    "\n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self,x):\n",
    "        return 0.5*x*(1+torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0/torch.pi))*\n",
    "            (x + 0.044715*torch.pow(x,3))\n",
    "\n",
    "        ))\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self,cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"],4*cfg[\"emb_dim\"]), ## Expansion\n",
    "            GELU(), ## Activation\n",
    "            nn.Linear(4*cfg[\"emb_dim\"],cfg[\"emb_dim\"]), ## Contraction\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Let us code a transformer block as follows:\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "Step 1: Shortcut connection for attention block\n",
    "\n",
    "Step 2: Shortcut connectin for feed forward block\n",
    "\n",
    "Step 3: Add the original input block\n",
    "\n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, num_heads, dropout, qkv_bias=True):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_head = d_out // num_heads\n",
    "        self.scale = self.d_head ** -0.5  # Scaling factor for attention scores\n",
    "\n",
    "        self.q_proj = nn.Linear(d_in, d_out, bias=qkv_bias)  # Query projection\n",
    "        self.k_proj = nn.Linear(d_in, d_out, bias=qkv_bias)  # Key projection\n",
    "        self.v_proj = nn.Linear(d_in, d_out, bias=qkv_bias)  # Value projection\n",
    "        self.out_proj = nn.Linear(d_out, d_out)  # Output projection\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, context=None, mask=None):\n",
    "        # If no context is provided, self-attention is performed\n",
    "        context = x if context is None else context\n",
    "\n",
    "        # Compute Query, Key, and Value matrices\n",
    "        Q = self.q_proj(x)  # [batch_size, seq_len, d_out]\n",
    "        K = self.k_proj(context)  # [batch_size, seq_len, d_out]\n",
    "        V = self.v_proj(context)  # [batch_size, seq_len, d_out]\n",
    "\n",
    "        # Reshape for multi-head attention\n",
    "        Q = Q.view(Q.shape[0], Q.shape[1], self.num_heads, self.d_head).transpose(1, 2)\n",
    "        K = K.view(K.shape[0], K.shape[1], self.num_heads, self.d_head).transpose(1, 2)\n",
    "        V = V.view(V.shape[0], V.shape[1], self.num_heads, self.d_head).transpose(1, 2)\n",
    "\n",
    "        # Compute scaled dot-product attention\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) * self.scale\n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask == 0, float('-inf'))\n",
    "        attn_weights = torch.softmax(attn_scores, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # Compute the attention output\n",
    "        attn_output = torch.matmul(attn_weights, V)  # [batch_size, num_heads, seq_len, d_head]\n",
    "\n",
    "        # Reshape back to original dimensions\n",
    "        attn_output = attn_output.transpose(1, 2).contiguous().view(x.shape[0], x.shape[1], -1)\n",
    "\n",
    "        # Apply the output projection\n",
    "        output = self.out_proj(attn_output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self,cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in = cfg[\"emb_dim\"],\n",
    "            d_out = cfg[\"emb_dim\"],\n",
    "            context_length= cfg[\"context_length\"],\n",
    "            num_heads = cfg[\"n_heads\"],\n",
    "            dropout = cfg[\"drop_rate\"],\n",
    "            qkv_bias = cfg[\"qkv_bias\"]\n",
    "        )\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self,x):\n",
    "        # Shortcut connection for attention block\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)  # Shpae [batch_size, num_tokens,emb_size]\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut # Add the original input back\n",
    "\n",
    "        # Shortcut connectin for feed forward block\n",
    "\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut # Add the original input back\n",
    "\n",
    "        return x \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "The given code defines a TransformerBlock class in PyTorch that includes a multi-head attention mechanism (MultiHeadAttention) and a feed forward network (FeedForward), both configured based on a provided configuration dictionary (cfg), such as GPT_CONFIG_124M.\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Using the GPT_CONFIG_124M dictionary we defined earlier, let's instantiate a transformer block and feed it some sample data\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Create sample input of shape [batch_size,num_tokens,emb_dim]\n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# torch.manual_seed(123)\n",
    "# x = torch.rand(2,4,768) #A\n",
    "# block = TransformerBlock(GPT_CONFIG_124M)\n",
    "# output = block(x)\n",
    "# print(\"Input shape:\",x.shape)\n",
    "# print(\"Output shape:\",output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT ARCHITECTURE PART 6: ENTIRE GPT MODEL ARCHITECTURE IMPLEMENTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,       # Vocabulary size\n",
    "    \"context_length\": 1024,    # Context length\n",
    "    \"emb_dim\": 768,            # Embedding dimension\n",
    "    \"n_heads\": 12,             # Number of attention heads\n",
    "    \"n_layers\": 12,            # Number of layers\n",
    "    \"drop_rate\": 0.1,          # Dropout rate\n",
    "    \"qkv_bias\": False          # Query-Key-Value bias\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "We started with this: A dummy GPT model class\n",
    "<div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self,cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"],cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"],cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "        # Use a placeholder for TransformerBlock\n",
    "        self.trf_block = nn.Sequential(\n",
    "            *[DummyTransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
    "\n",
    "        )\n",
    "\n",
    "        # Use a placeholder for LayerNorm\n",
    "        self.final_norm = DummyLayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"],cfg[\"vocab_size\"],bias = False\n",
    "        )\n",
    "\n",
    "    def forward(self,in_idx):\n",
    "        batch_size,seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len,device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds # Shape [ batch_size,num_tokens, emb_size]\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_block(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch:\n",
      " tensor([[6109, 4040, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      "\n",
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[-0.9289,  0.2748, -0.7557,  ..., -1.6070,  0.2702, -0.5888],\n",
      "         [-0.8606,  1.3502, -0.2798,  ..., -0.6376,  1.4690,  1.2530],\n",
      "         [ 0.5680,  1.6053, -0.2155,  ...,  1.1624,  0.1380,  0.7425],\n",
      "         [ 0.0447,  2.4787, -0.8843,  ...,  1.3219, -0.0864, -0.5856]],\n",
      "\n",
      "        [[-1.5474, -0.0542, -1.0571,  ..., -1.8061, -0.4494, -0.6747],\n",
      "         [-0.8422,  0.8243, -0.1098,  ..., -0.1434,  0.2079,  1.2046],\n",
      "         [ 0.1355,  1.1858, -0.1453,  ...,  0.0869, -0.1590,  0.1552],\n",
      "         [ 0.1666, -0.8138,  0.2307,  ...,  2.5035, -0.3055, -0.3083]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "out = model(batch)\n",
    "print(\"Input batch:\\n\",batch)\n",
    "print(\"\\nOutput shape:\",out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number o parameters: 77981184\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number o parameters: {total_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token embedding layer shape: torch.Size([50257, 768])\n",
      "Output layer shape: torch.Size([50257, 768])\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(\"Token embedding layer shape:\",model.tok_emb.weight.shape)\n",
    "print(\"Output layer shape:\",model.out_head.weight.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Lastly, let us compute the memory requiremetns of the 163 million parameters in our GPTModel object:\n",
    "<div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of the model:297.47 MB\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "total_size_bytes = total_params*4 #A\n",
    "total_size_mb = total_size_bytes / (1024*1024) #B\n",
    "print(f\"Total size of the model:{total_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT ARCHITECTURE PART 7: GENERATING TEXT FROM OUTPUT TOKENS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Let us implement the token-generatin process as follows:\n",
    "<div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Step 1:** `idx` is a `(batch, n_tokens)` array of indices in the current context.\n",
    "\n",
    "**Step 2:** Crop current context if it exceeds the supported context size.  \n",
    "E.g., if LLM supports only 5 tokens, and the context size is 10, then only the last 5 tokens are used as context.\n",
    "\n",
    "**Step 3:** Focus only on the last time step, so that `(batch, n_token, vocab_size)` becomes `(batch, vocab_size)`.\n",
    "\n",
    "**Step 4:** `probas` has shape `(batch, vocab_size)`.\n",
    "\n",
    "**Step 5:** `idx_next` has shape `(batch, 1)`.\n",
    "\n",
    "**Step 6:** Append sampled index to the running sequence, where `idx` has shape `(batch, n_tokens+1)`.\n",
    "\n",
    "\n",
    "<div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def generate_text_simple(model,idx,max_new_tokens, context_size):\n",
    "    # idx is (batch,n_tokens) array of indices in the current context\n",
    "    for _ in range(max_new_tokens):\n",
    "\n",
    "        # Crop current context if it exceeds the supported context size \n",
    "        # E.g, if LLM supports only 5 tokens, and the context size is 10\n",
    "        # then only the last 5 tokens are used as context\n",
    "        idx_cond = idx[:,-context_size:]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "\n",
    "        # (batch,n_tokens,vocab_size) becomes (batch,vocab_size)\n",
    "        logits  = logits[:,-1,:]\n",
    "\n",
    "        # Apply softmax to get probabilities\n",
    "        probas = torch.softmax(logits,dim=-1) # (batch,vocab_size)\n",
    "\n",
    "        # Get the idx of the vocab entry with the hightest probability value\n",
    "        idx_next = torch.argmax(probas,dim=-1,keepdim=True) #(batch,1)\n",
    "\n",
    "        # Append sampled index to the running sequence\n",
    "        idx = torch.cat((idx,idx_next),dim=-1) # (batch,n_tokens+1)\n",
    "\n",
    "    return idx \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded: [15496, 11, 314, 716]\n",
      "encoded_tensor.shape: torch.Size([1, 4])\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "start_context = \"Hello, I am\"\n",
    "encoded = tokenizer.encode(start_context)\n",
    "\n",
    "print(\"encoded:\",encoded)\n",
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0) #A\n",
    "print(\"encoded_tensor.shape:\",encoded_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: tensor([[15496,    11,   314,   716, 12170, 44251, 25952, 49216, 30322,  6868]])\n",
      "Output length: 10\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model.eval() # A\n",
    "out = generate_text_simple(\n",
    "    model = model,\n",
    "    idx = encoded_tensor,\n",
    "    max_new_tokens=6,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    "\n",
    "\n",
    ")\n",
    "print(\"Output:\",out)\n",
    "print(\"Output length:\",len(out[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am drone Omni SSLmyra muc native\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "As we can see, based on the preceding output, the model generated gibberish, which is not at all coherent text.\n",
    "\n",
    "What happened?\n",
    "\n",
    "The reason why the model is unable to produce coherent text is that we haven't trained it yet.\n",
    "\n",
    "So far, we just implemented the GPT architecture and initialized a GPT model instance with initial random weights.\n",
    "<div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Input token sequences\n",
    "inputs = torch.tensor([\n",
    "    [16833, 3626, 6100],  # [\"every effort moves\"]\n",
    "    [40, 1107, 588]       # [\"I really like\"]\n",
    "])\n",
    "\n",
    "# Target token sequences\n",
    "targets = torch.tensor([\n",
    "    [3626, 6100, 345],    # [\"effort moves you\"]\n",
    "    [1107, 588, 1131]     # [\"really like chocolate\"]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "\n",
    "probas = torch.softmax(logits,dim=-1) # Probability of each token in vocab\n",
    "print(probas.shape)  # Shpae: (batch_size,num_tokens,vocab_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toekn IDs:\n",
      " tensor([[[25388],\n",
      "         [41068],\n",
      "         [49272]],\n",
      "\n",
      "        [[ 2109],\n",
      "         [ 3957],\n",
      "         [30269]]])\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "token_ids=torch.argmax(probas,dim=-1,keepdim=True)\n",
    "print(\"Toekn IDs:\\n\",token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you horizontRoomki laserutfucks Levels Nice Sir dentist\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "import torch\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)  # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)  # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "We use a relatively small dataset for training the LLM (in fact, only one short story)\n",
    "\n",
    "The reasons are:\n",
    "\n",
    "You can run the code examples in a few minutes on a laptop computer without a suitable GPU.\n",
    "\n",
    "The training finishes relatively fast (minutes instead of weeks), which is good for educational purposes.\n",
    "We use a text from the public domain, which can be included in this GitHub repository without violating any usage rights.\n",
    "For example, Llama 2 7B required 184,320 GPU hours on A100 GPUs to be trained on 2 trillion tokens.\n",
    "At the time of this writing, the hourly cost of an 8xA100 cloud server at AWS is approximately 30 dollars.\n",
    "So, via an off-the-envelope calculation, training this LLM would cost 184,320 / 8 * 30 = 690,000 dollars.\n",
    "<div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "\n",
    "file_path = \"text_data/the-verdict.txt\"\n",
    "\n",
    "\n",
    "\n",
    "if  os.path.exists(file_path):\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_data = file.read()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "A   quick check that the text loaded ok by printing the first and last 100 words\n",
    "<div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# First 100 words of the text\n",
    "print(text_data[:99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Last 100 words of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens:: 5145\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "\n",
    "print(\"Characters:\",total_characters)\n",
    "print(\"Tokens::\",total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "With 5,145 tokens, the text is very short for training an LLM, but again, it's for educational purposes.\n",
    "Next, we divide the dataset into a training and a validation set and use the data loaders from chapter 2.\n",
    "\n",
    "Since we train the LLM to predict the next word in the text, the targets look the same as these inputs, except that the targets are shifted by one position.\n",
    "<div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPLEMENTING THE DATALOADER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self,txt,tokenizer,max_length,stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "\n",
    "        # Tokenize the entire text\n",
    "        token_ids = tokenizer.encode(txt,allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
    "\n",
    "        for i in range(0,len(token_ids) - max_length,stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def create_dataloader_v1(txt,batch_size=4,max_length=256,stride=128,shuffle=True, drop_last=True,num_workers=0):\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    #Create dataset\n",
    "    dataset = GPTDatasetV1(txt,tokenizer,max_length,stride)\n",
    "\n",
    "    #Create dataloader\n",
    "    dataloader =  DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    ) \n",
    "\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TransformerBlock' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[108], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m logits\n\u001b[0;32m     28\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m123\u001b[39m)\n\u001b[1;32m---> 29\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mGPTModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mGPT_CONFIG_124M\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m model\u001b[38;5;241m.\u001b[39meval(); \u001b[38;5;66;03m# Disaable dropout during inference\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[108], line 9\u001b[0m, in \u001b[0;36mGPTModel.__init__\u001b[1;34m(self, cfg)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_emb \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mEmbedding(cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext_length\u001b[39m\u001b[38;5;124m\"\u001b[39m],cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memb_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_emb \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mDropout(cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrf_block \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[1;32m----> 9\u001b[0m     \u001b[38;5;241m*\u001b[39m[TransformerBlock(cfg) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_layers\u001b[39m\u001b[38;5;124m\"\u001b[39m])]\n\u001b[0;32m     10\u001b[0m \n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_norm \u001b[38;5;241m=\u001b[39m LayerNorm(cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memb_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_head \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\n\u001b[0;32m     14\u001b[0m     cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memb_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m], cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvocab_size\u001b[39m\u001b[38;5;124m\"\u001b[39m], bias \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     15\u001b[0m )\n",
      "Cell \u001b[1;32mIn[108], line 9\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_emb \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mEmbedding(cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext_length\u001b[39m\u001b[38;5;124m\"\u001b[39m],cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memb_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_emb \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mDropout(cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrf_block \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[1;32m----> 9\u001b[0m     \u001b[38;5;241m*\u001b[39m[\u001b[43mTransformerBlock\u001b[49m(cfg) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_layers\u001b[39m\u001b[38;5;124m\"\u001b[39m])]\n\u001b[0;32m     10\u001b[0m \n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_norm \u001b[38;5;241m=\u001b[39m LayerNorm(cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memb_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_head \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\n\u001b[0;32m     14\u001b[0m     cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memb_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m], cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvocab_size\u001b[39m\u001b[38;5;124m\"\u001b[39m], bias \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     15\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TransformerBlock' is not defined"
     ]
    }
   ],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self,cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"],cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"],cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "        self.trf_block = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
    "\n",
    "        )\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias = False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval(); # Disaable dropout during inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,       # Vocabulary size\n",
    "    \"context_length\": 256,     # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,            # Embedding dimension\n",
    "    \"n_heads\": 12,             # Number of attention heads\n",
    "    \"n_layers\": 12,            # Number of layers\n",
    "    \"drop_rate\": 0.1,          # Dropout rate\n",
    "    \"qkv_bias\": False          # Query-key-value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Train/validation ratio\n",
    "train_ratio = 0.90\n",
    "\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "\n",
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the training loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"increase the `training_ratio`\")\n",
    "\n",
    "if total_tokens * (1 - train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the validation loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"decrease the `training_ratio`\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "An optional check that the data was loaded correctly:\n",
    "<div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "9\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(len(train_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens: 4608\n",
      "Validation tokens: 512\n",
      "All tokens: 5120\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print(\"Training tokens:\", train_tokens)\n",
    "print(\"Validation tokens:\", val_tokens)\n",
    "print(\"All tokens:\", train_tokens + val_tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here is the GPT Model class we coded earlier. We will need this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        # Ensure d_out is divisible by num_heads\n",
    "        assert (d_out % num_heads == 0), \"d_out must be divisible by num_heads\"\n",
    "        \n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads  # Projection dimension per head\n",
    "        \n",
    "        # Linear layers for Query, Key, and Value\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        \n",
    "        # Output projection layer\n",
    "        self.out_proj = nn.Linear(d_out, d_out)  # Combine outputs from all heads\n",
    "        \n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Register a causal mask for self-attention\n",
    "        self.register_buffer(\n",
    "            \"mask\", \n",
    "            torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input shape: (batch_size, num_tokens, d_in)\n",
    "        b, num_tokens, d_in = x.shape\n",
    "        \n",
    "        # Project to Query, Key, Value\n",
    "        keys = self.W_key(x)    # Shape: (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "        \n",
    "        # Reshape for multi-head processing\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim).transpose(1, 2)  # Shape: (b, num_heads, num_tokens, head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        \n",
    "        # Compute scaled dot-product attention\n",
    "        attn_scores = queries @ keys.transpose(2, 3)  # Shape: (b, num_heads, num_tokens, num_tokens)\n",
    "        \n",
    "        # Apply causal mask\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]  # Adjust mask size to current context\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)  # Fill masked positions with -inf\n",
    "        \n",
    "        # Compute attention weights\n",
    "        attn_weights = torch.softmax(attn_scores / (keys.shape[-1] ** 0.5), dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)  # Apply dropout\n",
    "        \n",
    "        # Compute context vectors\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2)  # Shape: (b, num_tokens, num_heads, head_dim)\n",
    "        \n",
    "        # Combine heads\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec)  # Final projection\n",
    "        \n",
    "        return context_vec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Next, we implement a utility function to calculate the cross-entropy loss of a given batch.\n",
    "\n",
    "In addition, we implement a second utility function to compute the loss for a user-specified number of batches\n",
    "<div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# model.to(device)\n",
    "\n",
    "# torch.manual_seed(123)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     train_loss = calc_loss_loader(train_loader,model,device)\n",
    "#     val_loss = calc_loss_loader(val_loader,model,device)\n",
    "\n",
    "# print(\"Training loss:\",train_loss)\n",
    "# print(\"Validation loss:\",val_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()  # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)  # Calculate loss\n",
    "            loss.backward()  # Calculate loss gradients\n",
    "            optimizer.step()  # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel()  # Returns the total number of elements (or tokens) in the batch\n",
    "            global_step += 1\n",
    "\n",
    "                # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                    f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "            # Print a sample text after each epoch\n",
    "        generate_and_print_sample(\n",
    "                            model, tokenizer, device, start_context\n",
    "                        )\n",
    "    return train_losses,val_losses,track_tokens_seen\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Steps for Training the Model:**\n",
    "1. **Initialize lists to track losses and tokens seen**\n",
    "2. **Start the main training loop**\n",
    "3. **Reset loss gradients from previous batch iteration**\n",
    "4. **Calculate loss gradients**\n",
    "5. **Update model weights using loss gradients**\n",
    "6. **Optional evaluation step**\n",
    "7. **Print a sample text after each epoch**\n",
    "\n",
    "<div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'context_length'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[123], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m      6\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m123\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mGPTModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mGPT_CONFIG_124M\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     10\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(\n\u001b[0;32m     11\u001b[0m     model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0004\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m\n\u001b[0;32m     12\u001b[0m )\n",
      "Cell \u001b[1;32mIn[108], line 9\u001b[0m, in \u001b[0;36mGPTModel.__init__\u001b[1;34m(self, cfg)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_emb \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mEmbedding(cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext_length\u001b[39m\u001b[38;5;124m\"\u001b[39m],cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memb_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_emb \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mDropout(cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrf_block \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[1;32m----> 9\u001b[0m     \u001b[38;5;241m*\u001b[39m[TransformerBlock(cfg) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_layers\u001b[39m\u001b[38;5;124m\"\u001b[39m])]\n\u001b[0;32m     10\u001b[0m \n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_norm \u001b[38;5;241m=\u001b[39m LayerNorm(cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memb_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_head \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\n\u001b[0;32m     14\u001b[0m     cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memb_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m], cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvocab_size\u001b[39m\u001b[38;5;124m\"\u001b[39m], bias \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     15\u001b[0m )\n",
      "Cell \u001b[1;32mIn[108], line 9\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_emb \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mEmbedding(cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext_length\u001b[39m\u001b[38;5;124m\"\u001b[39m],cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memb_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_emb \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mDropout(cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrf_block \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[1;32m----> 9\u001b[0m     \u001b[38;5;241m*\u001b[39m[\u001b[43mTransformerBlock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_layers\u001b[39m\u001b[38;5;124m\"\u001b[39m])]\n\u001b[0;32m     10\u001b[0m \n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_norm \u001b[38;5;241m=\u001b[39m LayerNorm(cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memb_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_head \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\n\u001b[0;32m     14\u001b[0m     cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memb_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m], cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvocab_size\u001b[39m\u001b[38;5;124m\"\u001b[39m], bias \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     15\u001b[0m )\n",
      "Cell \u001b[1;32mIn[117], line 4\u001b[0m, in \u001b[0;36mTransformerBlock.__init__\u001b[1;34m(self, cfg)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,cfg):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39matt \u001b[38;5;241m=\u001b[39m \u001b[43mMultiHeadAttention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43md_in\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43memb_dim\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43md_out\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43memb_dim\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontext_length\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn_heads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdrop_rate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mqkv_bias\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mqkv_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mff \u001b[38;5;241m=\u001b[39m FeedForward(cfg)\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1 \u001b[38;5;241m=\u001b[39m LayerNorm(cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memb_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'context_length'"
     ]
    }
   ],
   "source": [
    "# Note:\n",
    "# Uncomment the following code to calculate the execution time\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), lr=0.0004, weight_decay=0.1\n",
    ")\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Note:\n",
    "# Uncomment the following code to show the execution time\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DECODING STRRATEGIES TO CONTROL RANDOMENESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.to(\"cpu\")\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {\n",
    "    \"closer\": 0,\n",
    "    \"every\": 1,\n",
    "    \"effort\": 2,\n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5,\n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "}\n",
    "\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'closer',\n",
       " 1: 'every',\n",
       " 2: 'effort',\n",
       " 3: 'forward',\n",
       " 4: 'inches',\n",
       " 5: 'moves',\n",
       " 6: 'pizza',\n",
       " 7: 'toward',\n",
       " 8: 'you'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverse_vocab \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6.0907e-02, 1.6313e-03, 1.0019e-04, 5.7212e-01, 3.4190e-03, 1.3257e-04,\n",
      "        1.0120e-04, 3.5758e-01, 4.0122e-03])\n",
      "3\n",
      "forward\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "\n",
    "print(probas)\n",
    "\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "\n",
    "print(next_token_id)\n",
    "\n",
    "print(inverse_vocab[next_token_id])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toward\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas,num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 x closer\n",
      "2 x every\n",
      "0 x effort\n",
      "544 x forward\n",
      "2 x inches\n",
      "1 x moves\n",
      "0 x pizza\n",
      "376 x toward\n",
      "4 x you\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123)  # Manual seed for reproducibility\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "\n",
    "print_sampled_tokens(probas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1f1c5fd45b0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)\n",
    "\n",
    "# Temperature values\n",
    "temperatures = [1, 0.1, 5]  # Original, higher confidence, and lower confidence\n",
    "\n",
    "# Calculate scaled probabilities\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]\n",
    "\n",
    "# Plotting\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probas[i], bar_width, label=f'Temperature = {T}')\n",
    "\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DECODING STRATEGY 2 TOP-K SAMPLING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "Top positions: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits,top_k)\n",
    "print(\"Top logits:\", top_logits)\n",
    "print(\"Top positions:\",top_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_logits = torch.where(\n",
    "    condition=next_token_logits < top_logits[-1],\n",
    "    input = torch.tensor(float(\"-inf\")),\n",
    "    other=next_token_logits\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "print(new_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Lastly, let's apply the softmax function to turn these into next-token probabilities:\n",
    "<div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "topk_probas = torch.softmax(new_logits,dim=0)\n",
    "print(topk_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Temperature Scaling and Top-K sampling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "## Steps for Sequence Generation with Temperature and Top-K Sampling\n",
    "\n",
    "1. **For-loop is the same as before**: \n",
    "   - Get logits from the model.\n",
    "   - Focus only on the logits of the last time step.\n",
    "\n",
    "2. **Filter logits with Top-K Sampling**:\n",
    "   - Retain only the top `k` logits while setting others to a very low value (e.g., `-inf`) to focus on the most probable tokens.\n",
    "\n",
    "3. **Apply Temperature Scaling**:\n",
    "   - Scale the logits by dividing them with the specified temperature value.\n",
    "   - Use the softmax function to convert scaled logits into probabilities.\n",
    "\n",
    "4. **Carry out Greedy Next-Token Selection**:\n",
    "   - Select the token with the highest probability after applying temperature scaling if no sampling is performed.\n",
    "\n",
    "5. **Stop Early for End-of-Sequence Token**:\n",
    "   - If the `eos_id` (end-of-sequence token ID) is encountered during generation, terminate the sequence generation early.\n",
    "   <div/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "            logits = logits[:, -1, :]  # Focus on the last time step\n",
    "\n",
    "        # Top-K Sampling\n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(\n",
    "                logits < min_val, \n",
    "                torch.tensor(float(\"-inf\")).to(logits.device), \n",
    "                logits\n",
    "            )\n",
    "\n",
    "        # Temperature Scaling\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "\n",
    "        # Apply softmax to get probabilities\n",
    "        probs = torch.softmax(logits, dim=-1)\n",
    "\n",
    "        # Sample from the distribution\n",
    "        idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "\n",
    "        # Stop generating early if end-of-sequence token is encountered\n",
    "        if eos_id is not None and idx_next.item() == eos_id:\n",
    "            break\n",
    "\n",
    "        # Append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "\n",
    "    return idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m123\u001b[39m)\n\u001b[0;32m      3\u001b[0m token_ids \u001b[38;5;241m=\u001b[39m generate(\n\u001b[1;32m----> 4\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m,\n\u001b[0;32m      5\u001b[0m     idx\u001b[38;5;241m=\u001b[39mtext_to_token_ids(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvery effort moves you\u001b[39m\u001b[38;5;124m\"\u001b[39m, tokenizer),\n\u001b[0;32m      6\u001b[0m     max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m,\n\u001b[0;32m      7\u001b[0m     context_size\u001b[38;5;241m=\u001b[39mGPT_CONFIG_124M[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontext_length\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m      8\u001b[0m     top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m,\n\u001b[0;32m      9\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.4\u001b[39m\n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput text:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, token_ids_to_text(token_ids, tokenizer))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M['context_length'],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmstrach",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
